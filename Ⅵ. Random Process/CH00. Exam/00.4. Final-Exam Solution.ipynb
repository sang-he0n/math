{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ab880f",
   "metadata": {},
   "source": [
    "# CH00.4. **Final-term Examination Soltuion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4e39d",
   "metadata": {},
   "source": [
    "> ## Q1. **Compound Poisson Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5399767",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } J_{1}, J_{2}, \\cdots{} \\text{ be independent and identically distributed with zero mean}, \\text{ variance } \\, \\sigma{}_{J}^{2} $ \n",
    "#### $ \\text{and characteristic function } \\varPhi_{J}(u), \\; \\text{and let } ( N_{t} : t \\ge{} 0 ) \\text{ be a Poisson counting process with rate } \\lambda{} > 0, $ \n",
    "#### $ \\text{which is statistically independent of the } J\\text{'s}. \\; \\text{Define } Y_{t} \\, \\text{ for } \\, t \\ge{} 0 \\, \\text{ by } \\, Y_{t} = \\displaystyle{} \\sum_{i=1}^{N_{t}} J_{i}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6572345",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Show that } \\mathbb{E}[ Y_{t} ] = 0 \\, \\text{ for } \\, t \\ge{} 0 $\n",
    "##### $ \\text{(Hint: } \\mathbb{E}[ Y_{t} ] \\, \\text{ is the average of } \\, \\mathbb{E}[ Y_{t} \\mid{} N_{t} = n ] \\, \\text{ over } \\, n \\, \\text{ using the pmf of } N_{t} \\text{.)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6a8c6",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} (Y_{t} | N_{t}=n) = \\sum^{n}_{i=1}J_{i} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\mathbb{E}[Y_{t}|N_{t}=n] = \\mathbb{E}[\\sum^{n}_{i=1} J_{i}] = \\sum^{n}_{i=1} \\mathbb{E}[J_{i}] = n \\mu{} = 0 \\;\\; \\forall{} \\, n $ \n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\mathbb{E}[Y_{t}] = \\mathbb{E}\\bigg[{} \\mathbb{E}[Y_{t}|N_{t}] \\bigg]{}  = \\sum^{\\infty{}}_{n=0} \\mathbb{E}[Y_{t}|N_{t}=n] \\; \\mathbb{P}(N_{t}=n) \\;\\; \\because{} \\text{law of total expecatation(tower property)} $\n",
    "\n",
    "$ \\hspace{1.05cm} \\displaystyle{} = \\mathbb{E}[0] = \\sum^{\\infty{}}_{n=0} 0 \\; \\mathbb{P}(N_{t}=n) = 0 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\mathbb{E}[Y_{t}] = 0 \\, \\text{ for } \\, t \\geq{} 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd290972",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Briefly explain why } Y \\text{ has independent increments.} $ \n",
    "##### $ \\big({}\\text{Note: (a), (b) and the fact } \\, Y_{0} = 0 \\, \\text{ imply } ( Y_{t} : t \\ge{} 0 ) \\, \\text{ is a martingale.} \\big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd36167",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{Let } \\, Y \\text{ increment } S_{k} := Y_{t_{k}} - Y_{t_{k-1}}, \\text{ poisson incerement } \\, M_{k} := N_{t_{k}} - N_{t_{k-1}}, \\;\\; 0 \\leq{} t_{0} < t_{1} < \\cdots{} < t_{n}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} S_{k} = \\sum^{N_{t_{k}}}_{i=1} J_{i} - \\sum^{N_{t_{k-1}}}_{i=1} J_{i} = \\sum^{N_{t_{k}}}_{i=N_{t_{k-1}}+1} J_{i} = \\sum^{N_{t_{k-1}}+M_{k}}_{i=N_{t_{k-1}}+1} J_{i} \\;\\; \\because{} \\, N_{t_{k}} = N_{t_{k-1}} + M_{k} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{And let } \\, A_{1},\\cdots{},A_{n} \\subset{} \\mathbb{R} \\, \\text{ are borel sets, probability measure } \\, \\mathbb{P}, \\;\\; \\text{subset } \\, B := \\{ M_{1}=m_{1},\\cdots,M_{n}=m_{n} \\} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\cdot{} \\, \\text{Compute conditional probability} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} \\big( S_{1} \\in{} A_{1},\\cdots{},S_{n} \\in{} A_{n} \\mid{} B ) = \\prod^{n}_{k=1} \\mathbb{P} (S_{k} \\in{} A_{k} | S_{1} \\in{} A_{1}, \\cdots{}, S_{k-1} \\in{} A_{k-1}, B) \\;\\; \\because{} \\text{chain rule of conditional probability} $\n",
    "\n",
    "$ \\hspace{4.75cm} \\displaystyle{} = \\prod_{k=1}^{n} \\mathbb{P} \\big( S_{k} \\in{} A_{k} \\mid{} M_{k}=m_{k} \\big){} \\;\\; \\because{} \\{J_{i}\\} \\, \\text{ is i.i.d}, \\;\\; \\{J_{i}\\} \\perp{} (M_{1},\\cdots{},M_{n}), \\, \\text{ index sets are disjoint}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\cdot{} \\, \\text{Verify independency of } (S_{1}, \\cdots{}, S_{n}) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} \\big({} S_{1} \\in{} A_{1},\\cdots{},S_{n} \\in{} A_{n} \\big){} = \\sum_{m_{1}=0}^{\\infty{}} \\cdots{} \\sum_{m_{n}=0}^{\\infty{}} \\mathbb{P} \\big({} S_{1} \\in{} A_{1},\\cdots{},S_{n} \\in{} A_{n} \\mid{} M_{1}=m_{1},\\cdots{},M_{n}=m_{n} \\big){} \\, \\mathbb{P}(M_{1}=m_{1},\\cdots{},M_{n}=m_{n}) $\n",
    "\n",
    "$ \\hspace{4.2cm} \\displaystyle{} = \\sum_{m_{1}=0}^{\\infty{}} \\cdots{} \\sum_{m_{n}=0}^{\\infty{}} \\prod_{k=1}^{n} \\Big({} \\mathbb{P} ( S_{k} \\in{} A_{k} \\mid{} M_{k}=m_{k} ) \\, \\mathbb{P}(M_{k}=m_{k}) \\Big){} \\;\\; \\because{} (M_{1}, \\cdots{}, M_{n}) \\, \\text{ are mutually independent}. $\n",
    "\n",
    "$ \\hspace{4.2cm} \\displaystyle{} = \\prod_{k=1}^{n} \\Big({} \\sum_{m_{k}=0}^{\\infty{}} \\mathbb{P} ( S_{k} \\in{} A_{k} \\mid{} M_{k}=m_{k} ) \\, \\mathbb{P}(M_{k}=m_{k}) \\Big){} $\n",
    "\n",
    "$ \\hspace{4.2cm} \\displaystyle{} = \\prod_{k=1}^{n} \\mathbb{P} ( S_{k} \\in{} A_{k} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\Rrightarrow{} (S_{1}, \\cdots{}, S_{n}) = (Y_{t_{1}}-Y_{t_{0}}, \\cdots{}, Y_{t_{n}}-Y_{t_{n-1}}) \\, \\text{ is mutually independent}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\therefore{} Y \\text{ has independent increments.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f96408",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Express } \\, \\mathbb{E}[ Y_{t}^{2} ] \\, \\text{ and the characteristic function } \\, \\mathbb{E}[ e^{ j u Y_{t} } ] \\, \\text{ for } \\, t \\ge{} 0 \\text{ in terms of } \\, \\lambda{}, \\; \\sigma{}_{J}^{2} \\, \\text{ and } \\, \\varPhi{}_{J}. $\n",
    "##### $ \\text{(Hint: See hint for part (a))} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6b6cd",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Express } \\, \\mathbb{E}[ Y_{t}^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} (Y^{2}_{t} | N_{t} = n) = (\\sum^{n}_{i=1} J_{i})^{2} = \\sum^{n}_{i=1} J^{2}_{i} + 2 \\sum_{1\\leq{}i<k\\leq{}n} J_{i} J_{k} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[Y^{2}_{t} | N_{t} = n ] = \\mathbb{E}\\bigg[{} \\sum^{n}_{i=1} J^{2}_{i} + 2 \\sum_{1\\leq{}i<k\\leq{}n} J_{i} J_{k} \\bigg]{} = \\sum^{n}_{i=1} \\mathbb{E}[J^{2}_{i}] + 2 \\sum_{1\\leq{}i<k\\leq{}n} \\mathbb{E}[J_{i} J_{k}] $ \n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} = \\sum^{n}_{i=1} \\mathbb{E}[J^{2}_{i}] + 2 \\sum_{1\\leq{}i<k\\leq{}n} \\mathbb{E}[J_{i}] \\mathbb{E}[J_{k}] \\;\\; \\because{} (J_{1}, \\cdots{}, J_{n}) \\, \\text{ are mutually independent}. $\n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} = \\sum^{n}_{i=1} \\mathbb{E}[J^{2}_{i}] + 0 \\;\\; \\because{} \\mathbb{E}[J_{i}] = 0  $\n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} = n \\sigma{}_{J}^{2} \\;\\; \\because{} \\, \\{J_{i}\\} \\, \\text{ is i.i.d.}, \\;\\; \\text{var}(J_{i}) = \\mathbb{E}[J_{i}^{2}]= \\sigma{}^{2}_{J} $ \n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[Y^{2}_{t}] = \\mathbb{E}\\bigg[{} \\mathbb{E}[Y^{2}_{t}|N_{t}] \\bigg]{} = \\mathbb{E}[N_{t}\\sigma{}^{2}_{J}] = \\sigma{}^{2}_{J} \\mathbb{E}[N_{t}] = \\lambda{} t \\sigma{}^{2}_{J} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Express } \\, \\mathbb{E}[ e^{ j u Y_{t} } ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{Let } \\, \\varPhi{}_{J}(u) := \\mathbb{E}[e^{j u J_{1}}]. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}\\big[{} e^{j u Y_{t}} \\mid N_{t} = n \\big]{} = \\mathbb{E}\\Big[{} e^{j u \\sum_{i=1}^{n} J_{i}} \\Big]{} = \\mathbb{E}\\Big[{} \\prod_{i=1}^{n} e^{j u J_{i}} \\Big]{} = \\prod_{i=1}^{n} \\mathbb{E}[e^{j u J_{i}}] = \\big( \\varPhi{}_{J}(u) \\big)^{n} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[e^{j u Y_{t}}] = \\mathbb{E}\\big[{} \\mathbb{E}[e^{j u Y_{t}} \\mid N_{t}] \\big]{} = \\mathbb{E}\\big[{} \\varPhi{}_{J}(u)^{N_{t}} \\big]{} $\n",
    "\n",
    "$ \\hspace{1.55cm} \\displaystyle{} = \\sum_{n=0}^{\\infty{}} \\varPhi{}_{J}(u)^{n} \\, \\mathbb{P}(N_{t} = n) \\;\\; \\because{} N_{t} \\sim{} \\text{Pois}(\\lambda{} t) $\n",
    "\n",
    "$ \\hspace{1.55cm} \\displaystyle{} = \\sum_{n=0}^{\\infty{}} \\varPhi{}_{J}(u)^{n} \\, e^{-\\lambda{} t} \\frac{(\\lambda{} t)^{n}}{n!} = e^{-\\lambda{} t} \\sum_{n=0}^{\\infty{}} \\frac{\\big({} \\lambda{} t \\varPhi{}_{J}(u) \\big){}^{n}}{n!} $\n",
    "\n",
    "$ \\hspace{1.55cm} \\displaystyle{} = e^{\\big({} \\lambda{} t (\\varPhi_{J}(u) - 1) \\big){}} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[e^{j u Y_{t}}] = e^{\\big({} \\lambda{} t (\\varPhi_{J}(u) - 1) \\big){}} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\therefore{} \\mathbb{E}[Y^{2}_{t}] = \\lambda{} t \\sigma{}^{2}_{J}, \\;\\; \\mathbb{E}[e^{j u Y_{t}}] = e^{\\big({} \\lambda{} t (\\varPhi_{J}(u) - 1) \\big){}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25be0cc",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\text{Show that } ( Z_{t} : t \\ge{} 0 ) \\text{ defined by } Z_{t} = Y_{t}^{2} - c t \\, \\text{ is a martingale for some constant } \\, c, \\text{ and identify } \\, c. $\n",
    "##### $ \\text{(Hint: For } s < t, \\; Y_{t} = Y_{s} + ( Y_{t} - Y_{s} ) \\text{. It suffices to show that } \\mathbb{E}[ Z_{ t_{n+1} } \\mid{} Y_{ t_{1} }, \\cdots{}, Y_{ t_{n} } ] = Z_{ t_{n} } \\text{ whenever } t_{1} < \\cdots < t_{n+1}.) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34bb85",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{Let } \\, S_{n+1} := Y_{t_{n+1}} - Y_{t_{n}}., \\;\\; t \\geq{} 0, \\;\\; \\mathcal{G}_{n} := \\sigma{}(Y_{t_{0}},\\cdots{},Y_{t_{n}}) \\;\\; \\text{ where } \\, \\sigma{}(\\cdot{}) \\, \\text{ is sigma-algebra generated by } \\cdot{} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{t_{n+1}} = Y_{t_{n}} + S_{n+1}, \\;\\; Y_{t_{n+1}}^{2} = (Y_{t_{n}} + S_{n+1})^{2} = Y_{t_{n}}^{2} + 2 Y_{t_{n}} S_{n+1} + S_{n+1}^{2} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Expand conditional expectation}: $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ Z_{t_{n+1}} \\mid{} \\mathcal{G}_{n} ] = \\mathbb{E}[ Y_{t_{n+1}}^{2} - c t_{n+1} \\mid{} \\mathcal{G}_{n} ] = \\mathbb{E}[ Y_{t_{n}}^{2} + 2 Y_{t_{n}} S_{n+1} + S_{n+1}^{2} - c t_{n+1} \\mid{} \\mathcal{G}_{n} ] $\n",
    "\n",
    "$ \\hspace{2.25cm} \\displaystyle{} = Y_{t_{n}}^{2} + 2 Y_{t_{n}} \\mathbb{E}[ S_{n+1} \\mid{} \\mathcal{G}_{n} ] + \\mathbb{E}[ S_{n+1}^{2} \\mid{} \\mathcal{G}_{n} ] - c t_{n+1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ S_{n+1} \\mid{} \\mathcal{G}_{n} ] = \\mathbb{E}[ S_{n+1} ] \\;\\; \\because{} S_{n+1} \\perp{} \\mathcal{G}_{n} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ S_{n+1} ] = \\mathbb{E}[ Y_{t_{n+1}} - Y_{t_{n}} ] = \\mathbb{E}[Y_{t_{n+1}}] - \\mathbb{E}[Y_{t_{n}}] = 0 - 0 = 0 \\;\\; \\because{} \\mathbb{E}[Y_{t}] = 0, \\; t \\geq 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[ S_{n+1} \\mid{} \\mathcal{G}_{n} ] = 0 \\; \\Rightarrow{} \\; \\mathbb{E}[ Z_{t_{n+1}} \\mid{} \\mathcal{G}_{n} ] = Y_{t_{n}}^{2} + \\mathbb{E}[ S_{n+1}^{2} \\mid{} \\mathcal{G}_{n} ] - c t_{n+1} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Verify stationary increments}: $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} S_{n+1} = Y_{t_{n+1}} - Y_{t_{n}} = \\sum_{i=N_{t_{n}}+1}^{N_{t_{n+1}}} J_{i} \\;\\; \\because{} Y_{t} = \\sum_{i=1}^{N_{t}} J_{i} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{t} - Y_{s} = \\sum_{i=N_{s}+1}^{N_{t}} J_{i}, \\;\\; (N_{t}-N_{s}) \\sim{} \\text{Pois}(\\lambda{} (t-s)), \\;\\; \\{J_{i}\\} \\text{ is i.i.d.}, \\;\\; \\{J_{i}\\} \\perp{} (N_{t}) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Y_{t}-Y_{s} \\overset{d}{=} Y_{t-s} \\; \\Rightarrow{} \\; Y \\text{ has stationary increments} \\;\\; \\because{} \\text{distribution depends only on } t-s $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute second moment of } S_{n+1} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} S_{n+1} = Y_{t_{n+1}} - Y_{t_{n}} \\overset{d}{=} Y_{t_{n+1}-t_{n}} \\;\\; \\because{} Y \\text{ has stationary increments} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ S_{n+1}^{2} ] = \\mathbb{E}[ Y_{t_{n+1}-t_{n}}^{2} ] = \\lambda{} (t_{n+1}-t_{n}) \\sigma{}_{J}^{2} \\;\\; \\because{} \\mathbb{E}[Y_{t}^{2}] = \\lambda{} t \\sigma{}_{J}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ S_{n+1}^{2} \\mid{} \\mathcal{G}_{n} ] = \\mathbb{E}[ S_{n+1}^{2} ] = \\lambda{} (t_{n+1}-t_{n}) \\sigma{}_{J}^{2} \\;\\; \\because{} S_{n+1} \\perp{} \\mathcal{G}_{n} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[ Z_{t_{n+1}} \\mid{} \\mathcal{G}_{n} ] = Y_{t_{n}}^{2} + \\lambda{} (t_{n+1}-t_{n}) \\sigma{}_{J}^{2} - c t_{n+1} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Apply martingale condition}: $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ Z_{t_{n+1}} \\mid{} \\mathcal{G}_{n} ] = Z_{t_{n}} = Y_{t_{n}}^{2} - c t_{n} \\;\\; \\because{} \\text{For } (Z_{t}) \\text{ to be a martingale}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{t_{n}}^{2} + \\lambda{} (t_{n+1}-t_{n}) \\sigma{}_{J}^{2} - c t_{n+1} = Y_{t_{n}}^{2} - c t_{n} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\lambda{} (t_{n+1}-t_{n}) \\sigma{}_{J}^{2} - c (t_{n+1}-t_{n}) = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} c = \\lambda{} \\sigma{}_{J}^{2} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\therefore{} (Z_{t})_{t \\geq{} 0} \\, \\text{ is a martingale when } \\, c = \\lambda{} \\sigma{}_{J}^{2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd983b0",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344e14d",
   "metadata": {},
   "source": [
    "> ## Q2. **Brownian Bridge Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5823a",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } W = ( W_{t} : t \\ge{} 0 ) \\text{ be a standard Brownian motion } \\text{(i.e. a Brownian motion with parameter } \\sigma{}^{2} = 1 \\text{)}. $\n",
    "#### $ \\text{Let } B_{t} = W_{t} - t W_{1} \\, \\text{ for } \\, 0 \\le{} t \\le{} 1. \\; \\text{The process } \\, B = ( B_{t} : 0 \\le{} t \\le{} 1 ) \\, \\text{ is called a Brownian bridge process.} $\n",
    "#### $ \\text{Like } W, B \\, \\text{ is a mean zero Gaussian random process.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c240dc0",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Sketch a typical sample path of } \\, W \\text{ and the corresponding sample path of } \\, B. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1ab01",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Typical sample path of } \\, W : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} W_{0} = 0, \\; t \\mapsto{} W_{t} \\text{ is continuous, highly oscillatory, with no drift and not conditioned to be } 0 \\text{ at any fixed future time (e.g. } t = 1 \\text{).}  $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Typical sample path of } \\, B : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} B_{0} = W_{0} - 0 \\cdot{} W_{1} = 0, \\;\\; B_{1} = W_{1} - 1 \\cdot{} W_{1} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} t \\mapsto{} B_{t} \\, \\text{ is continuous, starts at } 0 \\text{ and is pinned to } 0 \\text{ at } t = 1, \\text{ fluctuating in between.} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{graphically, } W \\text{ looks like a free Brownian path, while } B \\text{ looks like a Brownian path constrained to hit } 0 \\, \\text{ at } \\, t = 1. $\n",
    "\n",
    "<p align=\"center\"> <img src=\"../img/00.3. Final-Exam (2).png\" width=\"50%\" height=\"50%\"></img> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd972eac",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Find the autocorrelation function of } \\, B. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d64ae5",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Mean of } B : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ B_{t} ] = \\mathbb{E}[ W_{t} - t W_{1} ] = \\mathbb{E}[ W_{t} ] - t \\mathbb{E}[ W_{1} ] = 0 - t \\cdot 0 = 0, \\;\\; 0 \\leq{} t \\leq{} 1 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Autocorrelation(covariance) of } B : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(s,t) := \\mathbb{E}[ B_{s} B_{t} ] \\;\\; 0 \\leq{} s,t \\leq{} 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} B_{t} = W_{t} - t W_{1}, \\;\\; B_{s} = W_{s} - s W_{1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ B_{s} B_{t} ] = \\mathbb{E}[ ( W_{s} - s W_{1} ) ( W_{t} - t W_{1} ) ] $\n",
    "\n",
    "$ \\hspace{1.675cm} \\displaystyle{} = \\mathbb{E}[ W_{s} W_{t} ] - t \\mathbb{E}[ W_{s} W_{1} ] - s \\mathbb{E}[ W_{t} W_{1} ] + s t \\mathbb{E}[ W_{1}^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{For standard Brownian motion, } \\, \\mathbb{E}[ W_{s} W_{t} ] = \\min{}(s,t), \\;\\; \\mathbb{E}[ W_{s} W_{1} ] = s, \\;\\; \\mathbb{E}[ W_{t} W_{1} ] = t, \\;\\; \\mathbb{E}[ W_{1}^{2} ] = 1 \\;\\; \\because{} \\text{stationary independent increments}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[ B_{s} B_{t} ] = \\min{}(s,t) - t s - s t + s t = \\min{}(s,t) - s t $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} R_{B}(s,t) = \\mathbb{E}[ B_{s} B_{t} ] = \\min{}(s,t) - s t \\;\\; 0 \\leq{} s,t \\leq{} 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4f17e",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Is } B \\text{ a Markov process?} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64968e6e",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Gaussian Markov criterion} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } X \\text{ is a mean zero Gaussian process, then } X \\text{ is Markov} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If and only if } \\; \\forall{} \\, 0 \\leq{} s \\leq{} t \\leq{} u \\leq{} 1, \\;\\; \\mathbb{E}[ X_{s} X_{u} ] = \\frac{ \\mathbb{E}[ X_{s} X_{t} ] \\; \\mathbb{E}[ X_{t} X_{u} ] }{ \\mathbb{E}[ X_{t}^{2} ] } $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Apply this to } X = B : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(s,t) = \\min{}(s,t) - s t, \\;\\; R_{B}(t,t) = t - t^{2} = t(1-t) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Fix } 0 \\leq{} s \\leq{} t \\leq{} u \\leq{} 1. \\text{ Then } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(s,u) = \\min{}(s,u) - s u = s - s u = s(1-u) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(s,t) = \\min{}(s,t) - s t = s - s t = s(1-t) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(t,u) = \\min{}(t,u) - t u = t - t u = t(1-u) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\frac{ R_{B}(s,t) R_{B}(t,u) }{ R_{B}(t,t) } = \\frac{ s(1-t) \\cdot{} t(1-u) }{ t(1-t) } = s(1-u) = R_{B}(s,u) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{the Gaussian Markov criterion holds for } B. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} B \\text{ is a Markov process.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3e6e2",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\text{Show that } B \\text{ is independent of the random variable } W_{1}. $\n",
    "##### $ \\text{(This means that for any finite collection } t_{1}, \\cdots{}, t_{n} \\in{} [ 0, 1 ] \\text{, the random vector } ( B_{ t_{1} }, \\cdots{}, B_{ t_{n} } )^{T} \\text{ is independent of } W_{1} \\text{.)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfd405",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Joint Gaussian structure} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{The vector } \\begin{bmatrix} B_{t_{1}} \\\\ \\vdots{} \\\\ B_{t_{n}} \\\\ W_{1} \\end{bmatrix} \\text{ is jointly Gaussian} \\;\\; \\because{} B_{t} \\text{ and } W_{1} \\text{ are linear functionals of the Gaussian process } W. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute } \\text{Cov}( B_{t}, W_{1} ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Cov}( B_{t}, W_{1} ) = \\mathbb{E}[ B_{t} W_{1} ] - \\mathbb{E}[ B_{t} ] \\mathbb{E}[ W_{1} ] = \\mathbb{E}[ B_{t} W_{1} ] \\;\\; \\because{} \\mathbb{E}[ B_{t} ] = \\mathbb{E}[ W_{1} ] = 0 $\n",
    "\n",
    "$ \\hspace{2.35cm} \\displaystyle{} = \\mathbb{E}[ ( W_{t} - t W_{1} ) W_{1} ] = \\mathbb{E}[ W_{t} W_{1} ] - t \\mathbb{E}[ W_{1}^{2} ] $\n",
    "\n",
    "$ \\hspace{2.35cm} \\displaystyle{} = t - t \\cdot{} 1 = 0 \\;\\; \\because{} \\text{standard Brownian motion on } [0,1], \\;\\; \\mathbb{E}[ W_{t} W_{1} ] = t, \\;\\; \\mathbb{E}[ W_{1}^{2} ] = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{Cov}( B_{t}, W_{1} ) = 0 \\;\\; \\forall{} \\, t \\in{} [0,1] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Extend to finite collections} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Cov}( B_{t_{k}}, W_{1} ) = 0 \\;\\; \\text{ for } \\, k = 1,\\cdots{},n $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} [ B_{t_{1}},\\cdots{},B_{t_{n}} ]^{T} \\perp{} W_{1} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} B \\text{ is independent of } W_{1}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e4890",
   "metadata": {},
   "source": [
    "#### **(e)** $ \\big({} \\text{Due to J. L. Doob.} \\big){} \\text{ Let } X_{t} = ( 1 - t ) W_{ \\frac{ t }{ 1 - t } } \\, \\text{ for } \\, 0 \\le{} t < 1. \\text{ Let } X_{1} = 0. $\n",
    "#### $ \\text{Let } X \\text{ denote the random process } \\, X = ( X_{t} : 0 \\le{} t \\le{} 1 ). $\n",
    "#### $ \\text{Like } W, X \\text{ is a mean zero Gaussian random process. Find the autocorrelation function of } \\, X. $\n",
    "#### $ \\text{Can you draw any conclusions?} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38de8b",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Mean of } X : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{t} = (1-t) W_{ \\frac{t}{1-t} }, \\;\\; 0 \\leq{} t < 1 $ , \\;\\; X_{1} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ X_{t} ] = (1-t) \\mathbb{E}\\big[{} W_{ \\frac{t}{1-t} } \\big]{} = 0, \\;\\; \\mathbb{E}[ X_{1} ] = 0 $ \n",
    "\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X \\text{ is mean zero.} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Autocorrelation of } X : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } \\, R_{X}(s,t) := \\mathbb{E}[ X_{s} X_{t} ] \\;\\; 0 \\leq{} s,t \\leq{} 1. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{s} = (1-s) W_{ \\frac{s}{1-s} }, \\;\\; X_{t} = (1-t) W_{ \\frac{t}{1-t} } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} a(s) := \\frac{s}{1-s}, \\;\\; a(t) := \\frac{t}{1-t}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Since } s \\mapsto a(s) \\text{ is increasing on } [0,1), $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} s \\leq{} t \\; \\Leftrightarrow{} \\; a(s) \\leq{} a(t). $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{For standard Brownian motion, } \\mathbb{E}[ W_{a(s)} W_{a(t)} ] = \\min{}( a(s), a(t) ). $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{(i) Case } \\, s \\leq{} t < 1 : $\n",
    "\n",
    "$ \\hspace{0.6cm} \\displaystyle{} \\mathbb{E}[ X_{s} X_{t} ] = (1-s)(1-t) \\mathbb{E}\\big[{} W_{a(s)} W_{a(t)} \\big]{} $\n",
    "\n",
    "$ \\hspace{1.875cm} \\displaystyle{} = (1-s)(1-t) a(s) \\;\\; \\because{} a(s) = \\min{}( a(s), a(t) ) $\n",
    "\n",
    "$ \\hspace{1.875cm} \\displaystyle{} = (1-s)(1-t) \\frac{s}{1-s} = s(1-t) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{(ii) Case } \\, t \\leq{} s < 1 : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ X_{s} X_{t} ] = t(1-s) \\;\\; \\because{} \\text{symmetric} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} R_{X}(s,t) = \\mathbb{E}[ X_{s} X_{t} ] = \\begin{cases} s(1-t), & \\text{if } \\, s \\leq{} t \\\\ t(1-s), & \\text{if } \\, t \\leq{} s \\end{cases} $\n",
    "\n",
    "$ \\hspace{3.95cm} \\displaystyle{} = \\min{}(s,t) \\big({} 1 - \\max{}(s,t) \\big){} \\;\\; 0 \\leq{} s,t \\leq{} 1. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Comparison with the Brownian bridge } B : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} R_{B}(s,t) = \\min{}(s,t) - s t. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{if } \\, 0 \\leq{} s \\leq{} t \\leq{} 1, \\; R_{X}(s,t) = s(1-t) = s - s t = \\min{}(s,t) - s t = R_{B}(s,t). $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{if } \\, 0 \\leq{} t \\leq{} s \\leq{} 1, \\; R_{X}(s,t) = t(1-s) = t - s t = \\min{}(s,t) - s t = R_{B}(s,t). $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} R_{X}(s,t) = R_{B}(s,t) \\;\\; \\forall \\, 0 \\leq{} s,t \\leq{} 1. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X \\overset{d}{=} B $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d402f9",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb0210",
   "metadata": {},
   "source": [
    "> ## Q3. **Conditional Distribution of Gaussian**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacd123",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } X \\text{ and } Y \\text{ be jointly Gaussian random variables with zero mean}, $\n",
    "#### $ \\text{such that the vector } \\begin{bmatrix} X \\\\ Y \\end{bmatrix} \\text{ has covariance matrix } \\begin{bmatrix} 4 & 4 \\\\ 4 & 8 \\end{bmatrix}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7531bcf",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Find the conditional expectation } \\, \\mathbb{E}{[ e^{t X} \\mid{} Y ]} $\n",
    "#### $ (\\text{the answer must be a function of } \\, Y \\text{ and } \\, t.) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2d0b0",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute parameter of conditional distribution } \\, (X \\mid{} Y) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Sigma{} = \\begin{bmatrix} \\text{Var}(X) & \\text{Cov}(X,Y) \\\\ \\text{Cov}(Y,X) & \\text{Var}(Y) \\end{bmatrix} = \\begin{bmatrix} 4 & 4 \\\\ 4 & 8 \\end{bmatrix} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X \\mid{} Y = y \\sim{} \\mathcal{N}\\Big({} \\mu{}_{X|Y}(y), \\sigma{}^{2}_{X|Y} \\Big){} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mu{}_{X|Y}(y) = \\frac{ \\text{Cov}(X,Y) }{ \\text{Var}(Y) } y = \\frac{4}{8} y = \\frac{y}{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}^{2}_{X|Y} = \\text{Var}(X) - \\frac{ \\text{Cov}(X,Y)^{2} }{ \\text{Var}(Y) } = 4 - \\frac{4^{2}}{8} = 4 - 2 = 2 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X \\mid{} Y = y \\sim{} \\mathcal{N}\\Big({} \\frac{y}{2}, 2 \\Big){} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute } \\mathbb{E}[ e^{tX} \\mid{} Y ] : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } Z \\sim{} \\mathcal{N}(\\mu{},\\sigma{}^{2}), $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ e^{t Z} ] = \\exp\\Big({} t \\mu{} + \\frac{1}{2} \\sigma{}^{2} t^{2} \\Big){} \\;\\; \\because{} \\text{moment generating function of Gaussian} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ e^{t X} \\mid{} Y ] = \\exp\\Big({} t \\cdot{} \\frac{Y}{2} + \\frac{1}{2} \\cdot{} 2 t^{2} \\Big){} = \\exp\\Big({} \\frac{t}{2} Y + t^{2} \\Big){} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\mathbb{E}[ e^{t X} \\mid{} Y ] = \\exp\\big({} \\frac{t}{2} Y + t^{2} \\big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b3ba5",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Express the conditional probability } \\mathbb{P}{( | X | \\ge{} 4 \\mid{} Y )} \\text{ in terms of the standard Gaussian cdf } \\, \\varPhi{( u )} $ \n",
    "##### $ (\\text{Note} : \\varPhi{( u )} = \\frac{ 1 }{ \\sqrt{ 2 \\pi{} } } \\int_{ -\\infty{} }^{u} e^{ - x^{2} / 2 } \\, \\mathrm{d} x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b085b",
   "metadata": {},
   "source": [
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } \\mu{}(Y) := \\frac{Y}{2}, \\;\\; \\sigma{}^{2} = 2, \\;\\; \\sigma{} = \\sqrt{2} \\;\\; \\text{ where } \\, (X \\mid{} Y = y) \\sim{} \\mathcal{N}\\Big({} \\frac{y}{2}, 2 \\Big){} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use the conditional normal distribution} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}\\big({} X \\geq{} 4 \\mid{} Y \\big){} = 1 - \\varPhi{}\\Big({} \\frac{ 4 - \\mu{}(Y) }{ \\sigma{} } \\Big){} = 1 - \\varPhi{}\\Big({} \\frac{ 4 - \\frac{Y}{2} }{ \\sqrt{2} } \\Big){} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}\\big({} X \\leq{} -4 \\mid{} Y \\big){} = \\varPhi{}\\Big({} \\frac{ -4 - \\mu{}(Y) }{ \\sigma{} } \\Big){} = \\varPhi{}\\Big({} \\frac{ -4 - \\frac{Y}{2} }{ \\sqrt{2} } \\Big){} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{P}\\big({} |X| \\geq{} 4 \\mid{} Y \\big){} = \\mathbb{P}\\big({} X \\geq{} 4 \\mid{} Y \\big){} + \\mathbb{P}\\big({} X \\leq{} -4 \\mid{} Y \\big){} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\mathbb{P}\\big({} |X| \\geq{} 4 \\mid{} Y \\big){} = 1 - \\varPhi{}\\Big({} \\frac{ 4 - \\frac{Y}{2} }{ \\sqrt{2} } \\Big){} + \\varPhi{}\\Big({} \\frac{ -4 - \\frac{Y}{2} }{ \\sqrt{2} } \\Big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93797fd8",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad286c",
   "metadata": {},
   "source": [
    "> ## Q4. **Poisson Counting Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d813a",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } N = ( N_{t} : t \\ge{} 0 ) \\text{ be a Poisson counting process with rate } \\lambda{} > 0. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c13c9",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Give a simple expression for } \\, \\mathbb{P}{( N_{1} \\geq{} 1 \\mid{} N_{2} = 2 )} \\text{ in terms of } \\, \\lambda{}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbd6ca",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use conditional distribution of increments} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{given } N_{2} = 2, \\text{ two arrivals in } [0,2] \\text{ are equally likely to fall in } [0,1] \\text{ or } (1,2] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} N_{1} \\mid{} N_{2} = 2 \\sim{} \\text{Bin}\\big({} 2, \\frac{1}{2} \\big){} \\;\\; \\because{} \\text{stationary independent increments} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute conditional probability} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}( N_{1} \\geq{} 1 \\mid{} N_{2} = 2 ) = 1 - \\mathbb{P}( N_{1} = 0 \\mid{} N_{2} = 2 ) $\n",
    "\n",
    "$ \\hspace{3.375cm} \\displaystyle{} = 1 - \\bigg({} 1 - \\frac{1}{2} \\bigg){}^{2} = 1 - \\bigg({} \\frac{1}{2} \\bigg){}^{2} = 1 - \\frac{1}{4} = \\frac{3}{4} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\mathbb{P}( N_{1} \\geq{} 1 \\mid{} N_{2} = 2 ) = \\frac{3}{4} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b69b3",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Give a simple expression for } \\, \\mathbb{P}{( N_{2} = 2 \\mid{} N_{1} \\geq{} 1 )} \\text{ in terms of } \\, \\lambda{}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75703eb",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} N_{1} \\sim{} \\text{Pois}(\\lambda{}), \\;\\; (N_{2} - N_{1}) \\sim{} \\text{Pois}(\\lambda{}), \\;\\; N_{1} \\perp{} ( N_{2} - N_{1} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute denominator } \\, \\mathbb{P}( N_{1} \\geq{} 1 ): $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}( N_{1} \\geq{} 1 ) = 1 - \\mathbb{P}( N_{1} = 0 ) = 1 - e^{-\\lambda{}} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute numerator } \\, \\mathbb{P}( N_{2} = 2, N_{1} \\geq{} 1 ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} N_{2} = N_{1} + ( N_{2} - N_{1} ) = 2, \\;\\; N_{1} \\geq{} 1 \\Rightarrow{} ( N_{1}, N_{2} - N_{1} ) \\in{} \\{ (1,1), (2,0) \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}( N_{2} = 2, N_{1} \\geq{} 1 ) = \\mathbb{P}( N_{1} = 1, N_{2} - N_{1} = 1 ) + \\mathbb{P}( N_{1} = 2, N_{2} - N_{1} = 0 ) $\n",
    "\n",
    "$ \\hspace{3.25cm} \\displaystyle{} = \\mathbb{P}( N_{1} = 1 ) \\mathbb{P}( N_{2} - N_{1} = 1 ) + \\mathbb{P}( N_{1} = 2 ) \\mathbb{P}( N_{2} - N_{1} = 0 ) $\n",
    "\n",
    "$ \\hspace{3.25cm} \\displaystyle{} = \\big( e^{-\\lambda{}} \\frac{\\lambda{}^{1}}{1!} \\big) \\big( e^{-\\lambda{}} \\frac{\\lambda{}^{1}}{1!} \\big) + \\big( e^{-\\lambda{}} \\frac{\\lambda{}^{2}}{2!} \\big) \\big( e^{-\\lambda{}} \\frac{\\lambda{}^{0}}{0!} \\big) $\n",
    "\n",
    "$ \\hspace{3.25cm} \\displaystyle{} = e^{-2\\lambda{}} \\lambda{}^{2} + e^{-2\\lambda{}} \\frac{\\lambda{}^{2}}{2} = \\frac{3}{2} e^{-2\\lambda{}} \\lambda{}^{2} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{}  \\mathbb{P}( N_{2} = 2 \\mid{} N_{1} \\geq{} 1 ) = \\frac{\\mathbb{P}( N_{2} = 2, N_{1} \\geq{} 1 )}{\\mathbb{P}( N_{1} \\geq{} 1 )} = \\frac{ \\frac{3}{2} e^{-2\\lambda{}} \\lambda{}^{2} }{ 1 - e^{-\\lambda{}} } $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef2234",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Let } X_{t} = N_{t}^{2}. \\, \\text{ Is } X = ( X_{t} : t \\ge{} 0 ) \\, \\text{ a time-homogeneous Markov process?} $\n",
    "#### $ \\text{If so, give the transition probabilities } \\, p_{ i j }( \\tau{} ) \\text{. If not, explain.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff222966",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{State space mapping} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} N_{t} \\in \\{ 0,1,2,\\cdots{} \\}, \\;\\; X_{t} = N_{t}^{2} \\in \\{ 0,1,4,9,\\cdots{} \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f : n \\mapsto{} n^{2} \\, \\text{ is a bijection from } \\{0,1,2,\\cdots{}\\} \\, \\text{ onto } \\, \\{0,1,4,9,\\cdots{}\\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} N \\, \\text{ is a time-homogeneous Markov process, and } \\, X_{t} = f( N_{t} ) \\, \\text{ with bijective } \\, f $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X \\, \\text{ is also a time-homogeneous Markov process} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Transition probabilities} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}( N_{t+\\tau{}} = j \\mid{} N_{t} = i ) = \\mathbb{P}( N_{t+\\tau{}} - N_{t} = j - i ) $\n",
    "\n",
    "$ \\hspace{3.575cm} \\displaystyle{} = \\begin{cases} e^{-\\lambda{} \\tau{}} \\dfrac{ ( \\lambda{} \\tau{} )^{ j - i } }{ ( j - i )! }, & \\text{if } \\, j \\geq{} i \\\\ 0, & \\text{if } \\, j < i \\end{cases} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} p_{ i^{2} , j^{2} }( \\tau{} ) := \\mathbb{P}( X_{t+\\tau{}} = j^{2} \\mid{} X_{t} = i^{2} ) $\n",
    "\n",
    "$ \\hspace{1.7cm} \\displaystyle{} = \\mathbb{P}( N_{t+\\tau{}} = j \\mid{} N_{t} = i ) $\n",
    "\n",
    "$ \\hspace{1.7cm} \\displaystyle{} = \\begin{cases} e^{-\\lambda{} \\tau{}} \\dfrac{ ( \\lambda{} \\tau{} )^{ j - i } }{ ( j - i )! }, & \\text{if } \\, j \\geq{} i \\\\ 0, & \\text{if } \\, j < i \\end{cases} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X = ( X_{t} )_{ t \\geq{} 0 } \\, \\text{ is a time-homogeneous Markov process}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb6767",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7d218",
   "metadata": {},
   "source": [
    "> ## Q5-1. **Kalman Filter for Range-Tracking Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225fd4b7",
   "metadata": {},
   "source": [
    "#### $ \\text{Consider} $\n",
    "#### $$ x_{ k+1 } = \\begin{bmatrix} 1 & \\Delta{} t & \\tfrac{ 1 }{ 2 } \\Delta{} t^{2} \\\\ 0 & 0 & \\Delta{} t \\\\ 0 & 0 & 1 \\end{bmatrix} x_{ k } + \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix} w_{ k } $$\n",
    "#### $$ y_{ k } = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} x_{ k } + v_{ k } $$\n",
    "#### $ \\text{where } \\{ w_{ k } \\} \\text{ and } \\{ v_{ k } \\} \\text{ are i.i.d. Gaussian random processes, which are independent of each other.} \\, \\text{ Here } x_{ k } = \\begin{bmatrix} x_{ k }^{(1)} \\\\ x_{ k }^{(2)} \\\\ x_{ k }^{(3)} \\end{bmatrix} $\n",
    "#### $ \\text{You may use any software, choose any } \\Delta{} t \\le{} 0.01, \\, \\text{ any noise/initial statistics.} $\n",
    "##### $ (\\text{The measurement data for } \\{ y_k \\} \\text{ is in ``Range.csv''. column1 : time, column2 : value}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d807e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# 0. import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================================================================\n",
    "# 1. load measurement data (Range.csv)\n",
    "data = pd.read_csv(filepath_or_buffer=\"../data/Range.csv\")\n",
    "t = data[\"Time\"].to_numpy()\n",
    "y = data[\"Range\"].to_numpy(dtype=float)\n",
    "n_steps = t.size\n",
    "\n",
    "# ===========================================================================\n",
    "# 2. define system matrices and noise statistics\n",
    "## (1) measurement matrix H, input matrix G\n",
    "H = np.array(object=[[1.0, 0.0, 0.0]])      # y_k = x_k^(1) + v_k\n",
    "G = np.array(object=[[0.0], [1.0], [1.0]])  # x_{k+1} = F x_k + G w_k\n",
    "\n",
    "## (2) noise variances (you can tune these)\n",
    "sigma_w = 10.0                              # std of process noise w_k\n",
    "sigma_v = 100.0                             # std of measurement noise v_k\n",
    "q = sigma_w**2                              # Var(w_k)\n",
    "r = sigma_v**2                              # Var(v_k)\n",
    "\n",
    "Q = q * (G @ G.T)                           # 3x3 process noise covariance\n",
    "R = np.array(object=[[r]])                  # 1x1 measurement noise covariance\n",
    "\n",
    "# ===========================================================================\n",
    "# 3. initialize filter\n",
    "## (1) state estimate and covariance containers\n",
    "x_hat = np.zeros(shape=(n_steps, 3))        # x_hat[k,:] = \\hat{x}_{k|k}\n",
    "P_seq = np.zeros(shape=(n_steps, 3, 3))     # P_seq[k,:,:] = P_{k|k}\n",
    "\n",
    "## (2) initial condition (rough choice)\n",
    "x_hat[0, :] = np.array(object=[y[0], 0.0, 0.0])\n",
    "P_seq[0, :, :] = np.diag(v=[1e6, 1e6, 1e6])\n",
    "\n",
    "I = np.eye(3)\n",
    "\n",
    "# ===========================================================================\n",
    "# 4. Kalman filter recursion (prediction + update)\n",
    "for k in range(1, n_steps):\n",
    "    # ---- (a) build F_k from time step Î”t_k\n",
    "    dt_k = t[k] - t[k - 1]\n",
    "    F_k = np.array(\n",
    "        object=[\n",
    "            [1.0,        dt_k, 0.5 * dt_k**2],\n",
    "            [0.0,        0.0,  dt_k],\n",
    "            [0.0,        0.0,  1.0],\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    # ---- (b) prediction\n",
    "    x_pred = F_k @ x_hat[k - 1, :]\n",
    "    P_pred = F_k @ P_seq[k - 1, :, :] @ F_k.T + Q\n",
    "\n",
    "    # ---- (c) update with measurement y_k\n",
    "    S = H @ P_pred @ H.T + R                 # innovation covariance (1x1)\n",
    "    K = P_pred @ H.T @ np.linalg.inv(S)      # Kalman gain (3x1)\n",
    "\n",
    "    innov = y[k] - (H @ x_pred)[0]           # scalar innovation\n",
    "    x_hat[k, :] = x_pred + (K[:, 0] * innov)\n",
    "    P_seq[k, :, :] = (I - K @ H) @ P_pred\n",
    "\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a3122",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Construct the Kalman filter to estimate the data.} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b21203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) Kalman filter model\n",
      "H (measurement matrix) :\n",
      "[[1. 0. 0.]]\n",
      "G (process noise input matrix) :\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Q (process noise covariance) : \n",
      "[[  0.   0.   0.]\n",
      " [  0. 100. 100.]\n",
      " [  0. 100. 100.]]\n",
      "R (measurement noise covariance) :\n",
      "[[10000.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"(a) Kalman filter model\")\n",
    "print(\"H (measurement matrix) :\")\n",
    "print(H)\n",
    "print(\"G (process noise input matrix) :\")\n",
    "print(G)\n",
    "print(\"Q (process noise covariance) : \")\n",
    "print(Q)\n",
    "print(\"R (measurement noise covariance) :\")\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f8152",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Plot your estimation.} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81264590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b) estimation summary\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps          : 1219\n",
      "Final time               : 340.0700\n",
      "Final estimate x_hat(T)  : [46841.84101345   137.93873222   137.93873222]\n",
      "Final range estimate     : 46841.8410\n"
     ]
    }
   ],
   "source": [
    "print(\"(b) estimation summary\")\n",
    "plt.figure()\n",
    "plt.plot(t, y, label=\"measurement $y_{k}$\")\n",
    "plt.plot(t, x_hat[:, 0], label=\"KF estimate $\\\\hat{x}_k^{(1)}$\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"range\")\n",
    "plt.title(\"Kalman filter estimate of range\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f\"Number of steps          : {n_steps}\")\n",
    "print(f\"Final time               : {t[-1]:.4f}\")\n",
    "print(f\"Final estimate x_hat(T)  : {x_hat[-1, :]}\")\n",
    "print(f\"Final range estimate     : {x_hat[-1, 0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd5d5a",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Plot } \\lvert{} x_{k}^{(1)} - \\hat{x}_{k}^{(1)} \\rvert{}^{2}, \\text{ i.e. empirical mean-square error.} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff889e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c) MSE proxy for x^(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of P11 over time    : 2151.0108\n",
      "Min,Max of P11           : 587.1558, 1000000.0000\n",
      "Time-varying curve of P11 is plotted in the figure.\n"
     ]
    }
   ],
   "source": [
    "mse_proxy = P_seq[:, 0, 0]\n",
    "print(\"(c) MSE proxy for x^(1)\")\n",
    "plt.figure()\n",
    "plt.plot(t, mse_proxy)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$P_{k|k}(1,1)$\")\n",
    "plt.title(\"proxy of MSE for first state (P11)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(f\"Mean of P11 over time    : {np.mean(mse_proxy):.4f}\")\n",
    "print(f\"Min,Max of P11           : {np.min(mse_proxy):.4f}, {np.max(mse_proxy):.4f}\")\n",
    "print(\"Time-varying curve of P11 is plotted in the figure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9258504",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\text{Discuss the convergence of the error covariance matrix.} $\n",
    "#### $ \\text{And you have to plot the error covariance matrix} $ \n",
    "##### $ \\text{(x-axis: time, y-axis: value of error covariance matrix (each component)).} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e90887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d) convergence of error covariance matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The diagonal entries P11, P22, P33 start from very large values due to the highly uncertain initial state.\n",
      " As measurements are incorporated, they decrease rapidly and then stabilize around constant positive levels.\n",
      " This shows that the error covariance P_k|k converges to a steady-state value, not to zero,\n",
      "  because process and measurement noise keep the estimation error variance strictly positive.\n"
     ]
    }
   ],
   "source": [
    "P11 = P_seq[:, 0, 0]\n",
    "P22 = P_seq[:, 1, 1]\n",
    "P33 = P_seq[:, 2, 2]\n",
    "print(\"(d) convergence of error covariance matrix\")\n",
    "plt.figure()\n",
    "plt.plot(t, P11, label=\"P11 (state 1)\")\n",
    "plt.plot(t, P22, label=\"P22 (state 2)\")\n",
    "plt.plot(t, P33, label=\"P33 (state 3)\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"error covariance\")\n",
    "plt.title(\"convergence of error covariance matrix (diagonal)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\n",
    "    \" The diagonal entries P11, P22, P33 start from very large values due to the highly uncertain initial state.\\n\"\n",
    "    \" As measurements are incorporated, they decrease rapidly and then stabilize around constant positive levels.\\n\"\n",
    "    \" This shows that the error covariance P_k|k converges to a steady-state value, not to zero,\\n\"\n",
    "    \"  because process and measurement noise keep the estimation error variance strictly positive.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3766d",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc17e7a",
   "metadata": {},
   "source": [
    "> ## Q5-2. **Scalar Kalman Filter Steady State**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73275512",
   "metadata": {},
   "source": [
    "#### $ \\text{Consider the following oneâ€“dimensional Kalman filter model} : $\n",
    "#### $$ x_{ k+1 } = f\\, x_{ k } + w_{ k }, y_{ k } = x_{ k } + v_{ k }, $$\n",
    "#### $ \\text{where } w_{ k } \\, \\text{ and } \\, v_{ k } \\, \\text{ are mutually independent Gaussian random variables with } \\, w_{ k }, v_{ k } \\sim N( 0, 1 ). $\n",
    "#### $ \\text{Assume the prior } x_{0} \\sim N( 0, \\sigma{}_{0}^{2} ). $\n",
    "#### $ \\text{From the standard Kalman filter equations, the estimation error variance } \\sigma{}_{k}^{2} = \\mathrm{Var}( x_{ k } - \\hat{x}_{k \\mid{} k-1} ) \\text{ satisfies} $\n",
    "#### $$ \\sigma{}_{k+1}^{2} = f^{2} \\sigma{}_{k}^{2} + 1 - \\frac{ f^{2} ( \\sigma{}_{k}^{2} )^{2} }{ \\sigma{}_{k}^{2} + 1 } $$\n",
    "#### $ \\text{and the Kalman gain is given by} $\n",
    "#### $$ K_{ k } = \\frac{ f\\, \\sigma{}_{k}^{2} }{ f^{2} \\sigma{}_{k}^{2} + 1 } . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962c195",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Show that} \\displaystyle{} \\lim_{ k \\to \\infty{} } \\sigma_{k}^{2} \\, \\text{ exists.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc74eeb",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Simplify the recursion and define } \\, T : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}_{k+1}^{2} = f^{2} \\sigma{}_{k}^{2} + 1 - \\frac{ f^{2} ( \\sigma{}_{k}^{2} )^{2} }{ \\sigma{}_{k}^{2} + 1 } $\n",
    "\n",
    "$ \\hspace{1.15cm} \\displaystyle{} = 1 + f^{2} \\Big({} \\sigma{}_{k}^{2} - \\frac{ ( \\sigma{}_{k}^{2} )^{2} }{ \\sigma{}_{k}^{2} + 1 } \\Big){} $\n",
    "\n",
    "$ \\hspace{1.15cm} \\displaystyle{} = 1 + f^{2} \\frac{ \\sigma{}_{k}^{2} ( \\sigma{}_{k}^{2} + 1 ) - ( \\sigma{}_{k}^{2} )^{2} }{ \\sigma{}_{k}^{2} + 1 } $\n",
    "\n",
    "$ \\hspace{1.15cm} \\displaystyle{} = 1 + f^{2} \\frac{ \\sigma{}_{k}^{2} }{ \\sigma{}_{k}^{2} + 1 } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\sigma{}_{k+1}^{2} = T( \\sigma{}_{k}^{2} ), \\;\\; T(x) := 1 + f^{2} \\frac{ x }{ x + 1 }, \\;\\; x \\geq{} 0 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Solve fixed point of } \\, T : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} x = T(x) \\;\\; \\Leftrightarrow{} \\;\\; x = 1 + f^{2} \\frac{ x }{ x + 1 } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} x( x + 1 ) = ( x + 1 ) + f^{2} x = x + 1 + f^{2} x $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} x^{2} + x = x + 1 + f^{2} x = ( f^{2} + 1 ) x + 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} x^{2} - f^{2} x - 1 = 0 \\; \\Leftrightarrow{} \\; x = \\dfrac{ f^{2} \\pm{} \\sqrt{ f^{4} + 4 } }{ 2 } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}_{*}^{2} := \\dfrac{ f^{2} + \\sqrt{ f^{4} + 4 } }{ 2 }, \\;\\; \\sigma{}_{-}^{2} := \\dfrac{ f^{2} - \\sqrt{ f^{4} + 4 } }{ 2 }, \\;\\; \\sqrt{ f^{4} + 4 } > \\lvert f^{2} \\rvert \\; \\Rightarrow{} \\; \\sigma{}_{-}^{2} < 0 < \\sigma{}_{*}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{unique positive fixed point } \\, \\sigma{}_{*}^{2} = \\dfrac{ f^{2} + \\sqrt{ f^{4} + 4 } }{ 2 } $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Sign of } \\, T(x) - x : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} T(x) - x = 1 + f^{2} \\frac{ x }{ x + 1 } - x = \\frac{ f^{2} x - x^{2} + 1 }{ x + 1 } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f^{2} x - x^{2} + 1 = - \\big({} x^{2} - f^{2} x - 1 \\big){} = - ( x - \\sigma{}_{*}^{2} )( x - \\sigma{}_{-}^{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} x \\geq{} 0 \\; \\Rightarrow{} \\; x + 1 > 0, \\; x - \\sigma{}_{-}^{2} > 0 \\;\\; \\because{} \\sigma{}_{-}^{2} < 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} x < \\sigma{}_{*}^{2} \\; \\Rightarrow{} \\; T(x) > x, \\;\\; x > \\sigma{}_{*}^{2} \\; \\Rightarrow{} \\; T(x) < x $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Monotonicity of } \\, T : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} T'(x) = f^{2} \\frac{ ( x + 1 ) - x }{ ( x + 1 )^{2} } = \\frac{ f^{2} }{ ( x + 1 )^{2} } > 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} T \\text{ is strictly increasing on } [ 0, \\infty{} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Bounds and monotonicity of } \\, ( \\sigma{}_{k}^{2} ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} 0 \\leq{} \\frac{ x }{ x + 1 } < 1, \\; x \\geq{} 0 \\; \\Rightarrow{} \\; 1 \\leq{} T(x) < 1 + f^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}_{0}^{2} \\geq{} 0 \\; \\Rightarrow{} \\; \\sigma{}_{1}^{2} = T( \\sigma{}_{0}^{2} ) \\in{} [ 1, 1 + f^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}_{k}^{2} \\in{} [ 1, 1 + f^{2} ] \\; \\Rightarrow{} \\; \\sigma{}_{k+1}^{2} = T( \\sigma{}_{k}^{2} ) \\in{} [ 1, 1 + f^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\sigma{}_{k}^{2} \\in{} [ 1, 1 + f^{2} ] \\;\\; \\forall{} k \\geq{} 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } \\sigma{}_{1}^{2} < \\sigma{}_{*}^{2}, \\;\\; \\sigma{}_{k}^{2} < \\sigma{}_{*}^{2} \\; \\Rightarrow{} \\; \\sigma{}_{k+1}^{2} = T( \\sigma{}_{k}^{2} ) > \\sigma{}_{k}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } \\sigma{}_{1}^{2} > \\sigma{}_{*}^{2}, \\;\\; \\sigma{}_{k}^{2} > \\sigma{}_{*}^{2} \\; \\Rightarrow{} \\; \\sigma{}_{k+1}^{2} = T( \\sigma{}_{k}^{2} ) < \\sigma{}_{k}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} ( \\sigma{}_{k}^{2} ) \\text{ is monotone and bounded in } [ 1, 1 + f^{2} ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\lim{}_{ k \\to \\infty{} } \\sigma{}_{k}^{2} \\text{ exists} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d3f2f",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Express the limit } \\, \\sigma{}_{\\infty{}}^{2}, \\text{ in terms of } f. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b97d17",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\sigma{}_{\\infty{}}^{2} = \\frac{ f^{2} + \\sqrt{ f^{4} + 4 } }{ 2 } \\;\\; \\because{} \\, \\text{By part (a), } \\; \\sigma{}_{\\infty{}}^{2} \\, \\text{ is the unique positive solution}: \\, x^{2} - f^{2} x - 1 = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9ca48",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Explain why } \\sigma{}_{\\infty{}}^{2} = 1 \\text{ if } f = 0. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1888a",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} f = 0 \\; \\Rightarrow{} \\; \\sigma{}_{k+1}^{2} = 0^{2} \\sigma{}_{k}^{2} + 1 - \\frac{ 0^{2} ( \\sigma{}_{k}^{2} )^{2} }{ \\sigma{}_{k}^{2} + 1 } = 1 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\sigma{}_{1}^{2} = 1, \\;\\; \\sigma{}_{k}^{2} = 1 \\;\\; \\forall{} \\, k \\geq 1 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\Rrightarrow{} \\lim{}_{k \\to \\infty{}} \\sigma{}_{k}^{2} = 1 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\sigma{}_{\\infty{}}^{2} = 1 \\;\\; \\text{if } f = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2bde9",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d1867",
   "metadata": {},
   "source": [
    "> ## Q6. **Conditional Independence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57b2cb",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } X, Y \\text{ and } Z \\text{ be three random variables with finite second moments, } $\n",
    "#### $ \\text{defined on a common probability space } ( \\Omega, \\mathcal{F}, P ). \\, \\text{ We say that } X \\text{ and } Z \\text{ are conditionally independent given } Y $ \n",
    "#### $ \\text{(and write } X \\to{} Y \\to{} Z ) \\, \\text{ if for any three events } A, B, C \\in \\mathcal{F}, $\n",
    "#### $$ P( X \\in A, Z \\in C \\mid{} Y \\in B ) = P( X \\in A \\mid{} Y \\in B ) P( Z \\in C \\mid{} Y \\in B ). $$\n",
    "#### $ \\text{If } X, Y \\text{ and } Z \\text{ have a joint pdf } \\, f_{ X Y Z }, \\text{ then conditional independence is equivalent to{}} $\n",
    "#### $$ f_{ X Z \\mid{} Y } ( x, z \\mid{} y ) = f_{ X \\mid{} Y } ( x \\mid{} y ) f_{ Z \\mid{} Y } ( z \\mid{} y ). $$\n",
    "#### $ \\text{When working on this problem, you may assume that all necessary joint pdf's exist.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e06b0",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{Given } X, \\text{ let } Y \\text{ and } Z \\text{ be defined by } Y = X + W_{1} \\text{ and } Z = Y + W_{2}, $\n",
    "#### $ \\text{where } X, W_{1} \\text{ and } W_{2} \\text{ are mutually independent random variables. Prove that } X \\to{} Y \\to{} Z. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82610f",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Joint pdf of } (X,Y,Z) \\text{ via transformation} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y = X + W_{1}, \\;\\; Z = Y + W_{2} = X + W_{1} + W_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Transformation } (x,w_{1},w_{2}) \\mapsto{} (x,y,z) = (x, x + w_{1}, x + w_{1} + w_{2}) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Inverse} : \\; x = x, \\; w_{1} = y - x, \\; w_{2} = z - y $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Jacobian determinant} = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{X,W_{1},W_{2}}(x,w_{1},w_{2}) = f_{X}(x) f_{W_{1}}(w_{1}) f_{W_{2}}(w_{2}) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} f_{X,Y,Z}(x,y,z) = f_{X}(x) f_{W_{1}}(y-x) f_{W_{2}}(z-y) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Marginal pdf of } Y : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{Y}(y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f_{X,Y,Z}(x,y,z) \\, \\mathrm{d}z \\, \\mathrm{d}x $\n",
    "\n",
    "$ \\hspace{1.3cm} \\displaystyle{} = \\int f_{X}(x) f_{W_{1}}(y-x) \\Big( \\int f_{W_{2}}(z-y) \\, \\mathrm{d}z \\Big) \\mathrm{d}x $\n",
    "\n",
    "$ \\hspace{1.3cm} \\displaystyle{} = \\int f_{X}(x) f_{W_{1}}(y-x) \\, \\mathrm{d}x \\;\\; \\because{} \\int f_{W_{2}}(z-y) \\, \\mathrm{d}z = 1 $\n",
    "\n",
    "$ \\hspace{1.3cm} \\displaystyle{} =: h(y) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Conditional pdf } f_{X \\mid{} Y} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{X \\mid{} Y}(x \\mid{} y) = \\frac{ f_{X,Y}(x,y) }{ f_{Y}(y) } = \\frac{ f_{X}(x) f_{W_{1}}(y-x) }{ h(y) } $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Conditional pdf } f_{Z \\mid{} Y} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{Y,Z}(y,z) = \\int f_{X,Y,Z}(x,y,z) \\, \\mathrm{d}x $\n",
    "\n",
    "$ \\hspace{1.9cm} \\displaystyle{} = \\int f_{X}(x) f_{W_{1}}(y-x) f_{W_{2}}(z-y) \\, \\mathrm{d}x $\n",
    "\n",
    "$ \\hspace{1.9cm} \\displaystyle{} = \\Big( \\int f_{X}(x) f_{W_{1}}(y-x) \\, \\mathrm{d}x \\Big) f_{W_{2}}(z-y) = h(y) f_{W_{2}}(z-y) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} f_{Z \\mid{} Y}(z \\mid{} y) = \\frac{ f_{Y,Z}(y,z) }{ f_{Y}(y) } = \\frac{ h(y) f_{W_{2}}(z-y) }{ h(y) } = f_{W_{2}}(z-y) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Conditional joint pdf } f_{X,Z \\mid{} Y} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{X,Z \\mid{} Y}(x,z \\mid{} y) = \\frac{ f_{X,Y,Z}(x,y,z) }{ f_{Y}(y) } = \\frac{ f_{X}(x) f_{W_{1}}(y-x) f_{W_{2}}(z-y) }{ h(y) } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} = \\Big( \\frac{ f_{X}(x) f_{W_{1}}(y-x) }{ h(y) } \\Big) f_{W_{2}}(z-y) = f_{X \\mid{} Y}(x \\mid{} y) f_{Z \\mid{} Y}(z \\mid{} y) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} f_{X,Z \\mid{} Y}(x,z \\mid{} y) = f_{X \\mid{} Y}(x \\mid{} y) f_{Z \\mid{} Y}(z \\mid{} y) \\; \\Rightarrow{} \\; X \\to{} Y \\to{} Z $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71665c",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Show that } X \\to{} Y \\to{} Z \\, \\text{ implies that } \\, \\mathbb{E}[ X \\mid{} Y, Z ] = \\mathbb{E}[ X \\mid{} Y ]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf7a0c",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use conditional independence in pdf form} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X \\to{} Y \\to{} Z \\; \\Rightarrow{} \\; f_{X,Z \\mid{} Y}(x,z \\mid{} y) = f_{X \\mid{} Y}(x \\mid{} y) f_{Z \\mid{} Y}(z \\mid{} y) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} f_{X \\mid{} Y,Z}(x \\mid{} y,z) = \\frac{ f_{X,Z \\mid{} Y}(x,z \\mid{} y) }{ f_{Z \\mid{} Y}(z \\mid{} y) } $\n",
    "\n",
    "$ \\hspace{2.675cm} \\displaystyle{} = \\frac{ f_{X \\mid{} Y}(x \\mid{} y) f_{Z \\mid{} Y}(z \\mid{} y) }{ f_{Z \\mid{} Y}(z \\mid{} y) } = f_{X \\mid{} Y}(x \\mid{} y) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute conditional expectations} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}[ X \\mid{} Y = y, Z = z ] = \\int_{-\\infty}^{\\infty} x f_{X \\mid{} Y,Z}(x \\mid{} y,z) \\, \\mathrm{d}x $\n",
    "\n",
    "$ \\hspace{3.5cm} \\displaystyle{} = \\int x f_{X \\mid{} Y}(x \\mid{} y) \\, \\mathrm{d}x = \\mathbb{E}[ X \\mid{} Y = y ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[ X \\mid{} Y,Z ] = \\mathbb{E}[ X \\mid{} Y ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X \\to{} Y \\to{} Z \\; \\Rightarrow{} \\; \\mathbb{E}[ X \\mid{} Y,Z ] = \\mathbb{E}[ X \\mid{} Y ] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad753b",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Show that if } X \\to{} Y \\to{} Z, \\text{ then } \\, \\text{MMSE}( X \\mid{} Z ) - \\text{MMSE}( X \\mid{} Y ) = \\mathbb{E}\\big[ ( \\mathbb{E}[ X \\mid{} Y ] - \\mathbb{E}[ X \\mid{} Z ] )^{2} \\big]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcfb6e1",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{Let } \\, m_{Y} := \\mathbb{E}[ X \\mid{} Y ], \\;\\; m_{Z} := \\mathbb{E}[ X \\mid{} Z ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\text{MMSE}( X \\mid{} Y ) = \\mathbb{E}\\big[ ( X - m_{Y} )^{2} \\big], \\;\\; \\text{MMSE}( X \\mid{} Z ) = \\mathbb{E}\\big[ ( X - m_{Z} )^{2} \\big] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use result from part (b)} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X \\to{} Y \\to{} Z \\; \\Rightarrow{} \\; \\mathbb{E}[ X \\mid{} Y,Z ] = m_{Y} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{E}[ X - m_{Y} \\mid{} Y,Z ] = 0 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Expand } \\text{MMSE}( X \\mid{} Z ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - m_{Z} = ( X - m_{Y} ) + ( m_{Y} - m_{Z} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( X - m_{Z} )^{2} = ( X - m_{Y} )^{2} + 2 ( X - m_{Y} )( m_{Y} - m_{Z} ) + ( m_{Y} - m_{Z} )^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}\\big[ ( X - m_{Z} )^{2} \\big] = \\mathbb{E}\\big[ ( X - m_{Y} )^{2} \\big] + 2 \\mathbb{E}\\big[ ( X - m_{Y} )( m_{Y} - m_{Z} ) \\big] + \\mathbb{E}\\big[ ( m_{Y} - m_{Z} )^{2} \\big] $\n",
    "\n",
    "$ \\hspace{2.675cm} \\displaystyle{} = \\text{MMSE}( X \\mid{} Y ) + 2 \\mathbb{E}\\big[ ( X - m_{Y} )( m_{Y} - m_{Z} ) \\big] + \\mathbb{E}\\big[ ( m_{Y} - m_{Z} )^{2} \\big] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}\\big[ ( X - m_{Y} )( m_{Y} - m_{Z} ) \\big] = \\mathbb{E}\\Big[ \\mathbb{E}\\big[ ( X - m_{Y} )( m_{Y} - m_{Z} ) \\mid{} Y,Z \\big] \\Big] $\n",
    "\n",
    "$ \\hspace{4.25cm} \\displaystyle{} = \\mathbb{E}\\Big[ ( m_{Y} - m_{Z} ) \\mathbb{E}\\big[ X - m_{Y} \\mid{} Y,Z \\big] \\Big] $\n",
    "\n",
    "$ \\hspace{4.25cm} \\displaystyle{} = \\mathbb{E}\\big[ ( m_{Y} - m_{Z} ) \\cdot 0 \\big] = 0 \\;\\; \\because{} \\mathbb{E}[ X - m_{Y} \\mid{} Y,Z ] = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{E}\\big[ ( X - m_{Z} )^{2} \\big] = \\mathbb{E}\\big[ ( X - m_{Y} )^{2} \\big] + \\mathbb{E}\\big[ ( m_{Y} - m_{Z} )^{2} \\big] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{MMSE}( X \\mid{} Z ) = \\text{MMSE}( X \\mid{} Y ) + \\mathbb{E}\\big[ ( m_{Y} - m_{Z} )^{2} \\big] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{MMSE}( X \\mid{} Z ) - \\text{MMSE}( X \\mid{} Y ) = \\mathbb{E}\\big[ ( \\mathbb{E}[ X \\mid{} Y ] - \\mathbb{E}[ X \\mid{} Z ] )^{2} \\big] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d0bb2",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a4265",
   "metadata": {},
   "source": [
    "> ## Q7. **Orthogonality Principle in $ \\, L^{2} $ space**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79415314",
   "metadata": {},
   "source": [
    "#### $ \\text{Prove Theorem } 3.2. \\text{ (a), (b), (c)}. $\n",
    "##### $ (\\text{Do not copy the proof from the textbook. You should write your own proof.}) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\textbf{THEOREM } 3.2 \\; \\text{(The orthogonality principle)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Let } V \\text{ be a closed, linear subspace of } L^{2}( \\Omega, \\mathcal{F}, P ) \\text{, and let } X \\in L^{2}( \\Omega, \\mathcal{F}, P ) \\text{, for some probability space } ( \\Omega, \\mathcal{F}, P ). $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(a) (Existence and uniqueness) There exists a unique element } Z^{*} \\text{ in } V \\text{ so that } \\mathbb{E}[ ( X - Z^{*} )^{2} ] \\le{} \\mathbb{E}[ ( X - Z )^{2} ] \\text{ for all } Z \\in V. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\big({} \\text{Here, we consider two elements } Z \\text{ and } Z' \\text{ of } V \\text{ to be the same if } P \\{ Z = Z' \\} = 1. \\; \\text{also } Z^{*} \\text{ denoted by } \\Pi_{ V }( X ) \\big){} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(b) (Characterization) Let } W \\text{ be a random variable. Then } W = Z^{*} \\text{ if and only if the following two conditions hold:} $\n",
    "\n",
    "$ \\hspace{0.75cm} \\text{(i) } W \\in V $\n",
    "\n",
    "$ \\hspace{0.75cm} \\text{(ii) } ( X - W ) \\perp Z \\text{ for all } Z \\in V. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(c) (Error expression) The minimum mean square error (MMSE) is given by } \\mathbb{E}[ ( X - Z^{*} )^{2} ] = \\mathbb{E}[ X^{2} ] - \\mathbb{E}[ ( Z^{*} )^{2} ]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac7eaa",
   "metadata": {},
   "source": [
    "#### **(a-proof)** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28e453",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Rewrite the MSE as a quadratic functional on } V : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} J( Z ) := \\mathbb{}{E}[ ( X - Z )^{2} ] = \\| X - Z \\|^{2} $\n",
    "\n",
    "$ \\hspace{1.325cm} \\displaystyle{} = \\mathbb{}{E}[ X^{2} ] - 2 \\mathbb{}{E}[ X Z ] + \\mathbb{}{E}[ Z^{2} ] $\n",
    "\n",
    "$ \\hspace{1.325cm} \\displaystyle{} = \\| X \\|^{2} - 2 \\langle X, Z \\rangle + \\| Z \\|^{2} $\n",
    "\n",
    "$ \\hspace{1.325cm} \\displaystyle{} = \\| Z \\|^{2} - 2 \\langle X, Z \\rangle + \\| X \\|^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} J( Z ) \\text{ is a continuous quadratic functional on the Hilbert space } V $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Strict convexity and uniqueness of the minimizer} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{1}, Z_{2} \\in{} V, \\;\\; Z_{1} \\neq{} Z_{2}, \\;\\; 0 < \\lambda{} < 1, \\;\\; Z_{\\lambda{}} := \\lambda{} Z_{1} + ( 1 - \\lambda{} ) Z_{2} \\in{} V $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} J( Z_{\\lambda{}} ) = \\| X - Z_{\\lambda{}} \\|^{2} = \\| \\lambda{}( X - Z_{1} ) + ( 1 - \\lambda{} )( X - Z_{2} ) \\|^{2} $\n",
    "\n",
    "$ \\hspace{1.35cm} \\displaystyle{} = \\lambda{}^{2} \\| X - Z_{1} \\|^{2} + ( 1 - \\lambda{} )^{2} \\| X - Z_{2} \\|^{2} + 2 \\lambda{} ( 1 - \\lambda{} ) \\langle X - Z_{1}, X - Z_{2} \\rangle $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\lambda{} J( Z_{1} ) + ( 1 - \\lambda{} ) J( Z_{2} ) = \\lambda{} \\| X - Z_{1} \\|^{2} + ( 1 - \\lambda{} ) \\| X - Z_{2} \\|^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} J( Z_{\\lambda{}} ) - \\big( \\lambda{} J( Z_{1} ) + ( 1 - \\lambda{} ) J( Z_{2} ) \\big){} = - \\lambda{} ( 1 - \\lambda{} ) \\| Z_{1} - Z_{2} \\|^{2} < 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} J( Z ) \\text{ is strictly convex on } V \\; \\Rightarrow{} \\; \\text{a minimizer (if it exists) is unique} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Existence and uniqueness via projection in } L^{2} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} d := \\inf{}_{ Z \\in{} V } \\| X - Z \\| $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\exists{}! \\, Z^{*} \\in{} V \\text{ such that } \\| X - Z^{*} \\| = d \\;\\; \\because{} L^{2}( \\Omega{}, \\mathcal{F}{}, P ) \\text{ Hilbert, } V \\text{ closed subspace (projection theorem)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} J( Z^{*} ) = \\| X - Z^{*} \\|^{2} = d^{2} \\leq{} \\| X - Z \\|^{2} = J( Z ) \\;\\; \\forall{} Z \\in{} V $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Z^{*} \\text{ exists in } V \\text{, minimizes } J \\text{ over } V \\text{ and is unique (strict convexity)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{There exists a unique } Z^{*} \\in{} V \\text{ such that } \\mathbb{}{E}[ ( X - Z^{*} )^{2} ] \\leq{} \\mathbb{}{E}[ ( X - Z )^{2} ] \\;\\; \\forall{} Z \\in{} V. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717f139",
   "metadata": {},
   "source": [
    "#### **(b-proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af7347",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{If } W = Z^{*}, \\text{ derive orthogonality} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Fix } Z \\in{} V, \\; \\alpha{} \\in{} \\mathbb{}{R}, \\; Z^{*} + \\alpha{} Z \\in{} V $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} J( Z^{*} + \\alpha{} Z ) = \\| X - ( Z^{*} + \\alpha{} Z ) \\|^{2} $\n",
    "\n",
    "$ \\hspace{2.3cm} \\displaystyle{} = \\| ( X - Z^{*} ) - \\alpha{} Z \\|^{2} $\n",
    "\n",
    "$ \\hspace{2.3cm} \\displaystyle{} = \\| X - Z^{*} \\|^{2} - 2 \\alpha{} \\langle{} X - Z^{*}, Z \\rangle{} + \\alpha{}^{2} \\| Z \\|^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z^{*} \\text{ minimizes } J \\; \\Rightarrow{} \\; J( Z^{*} + \\alpha{} Z ) - J( Z^{*} ) \\geq{} 0 \\;\\; \\forall{} \\alpha{} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} - 2 \\alpha{} \\langle{} X - Z^{*}, Z \\rangle{} + \\alpha{}^{2} \\| Z \\|^{2} \\geq{} 0 \\;\\; \\forall{} \\alpha{} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Quadratic in } \\alpha{} \\text{ has minimum } 0 \\, \\text{ only if } \\, \\langle{} X - Z^{*}, Z \\rangle{} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\langle{} X - Z^{*}, Z \\rangle{} = 0 \\;\\; \\forall{} Z \\in{} V \\text{ and } Z^{*} \\in{} V. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{If } W \\in{} V \\text{ and } ( X - W ) \\perp{} V, \\text{ show } W = Z^{*} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } Z \\in{} V, \\; W - Z \\in{} V $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\| X - Z \\|^{2} = \\| ( X - W ) + ( W - Z ) \\|^{2} = \\| X - W \\|^{2} + 2 \\langle{} X - W, W - Z \\rangle{} + \\| W - Z \\|^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( X - W ) \\perp{} V, \\; W - Z \\in{} V \\; \\Rightarrow{} \\; \\langle{} X - W, W - Z \\rangle{} = 0 $ \n",
    "\n",
    "$ \\hspace{4.875cm} \\Rightarrow{} \\; \\| X - Z \\|^{2} = \\| X - W \\|^{2} + \\| W - Z \\|^{2} \\geq{} \\| X - W \\|^{2} \\;\\; \\forall{} Z \\in{} V $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} W = Z^{*} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} W = Z^{*} \\iff \\big( W \\in{} V \\text{ and } ( X - W ) \\perp{} Z \\;\\; \\forall{} Z \\in{} V \\big){}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcb665",
   "metadata": {},
   "source": [
    "#### **(c-proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c85ce3",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Expand the squared error and use orthogonality} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}[ ( X - Z^{*} )^{2} ] = \\mathbb{}{E}[ X^{2} - 2 X Z^{*} + ( Z^{*} )^{2} ] $\n",
    "\n",
    "$ \\hspace{2.6cm} = \\mathbb{}{E}[ X^{2} ] - 2 \\mathbb{}{E}[ X Z^{*} ] + \\mathbb{}{E}[ ( Z^{*} )^{2} ] $\n",
    "\n",
    "$ \\hspace{2.6cm} = \\mathbb{}{E}[ X^{2} ] - 2 \\mathbb{}{E}[ ( Z^{*} )^{2} ] + \\mathbb{}{E}[ ( Z^{*} )^{2} ] $\n",
    "\n",
    "$ \\hspace{2.6cm} = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( Z^{*} )^{2} ] \\;\\; \\because{} ( X - Z^{*} ) \\perp{} Z^{*}, \\;\\; \\mathbb{}{E}[ ( X - Z^{*} ) Z^{*} ] = 0, \\;\\; \\mathbb{}{E}[ X Z^{*} ] = \\mathbb{}{E}[ ( Z^{*} )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{MMSE} = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( Z^{*} )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\mathbb{}{E}[ ( X - Z^{*} )^{2} ] = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( Z^{*} )^{2} ]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304f53c",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41613cd9",
   "metadata": {},
   "source": [
    "> ## Q8-1. **Linearity of Orthogonal Projection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934bd5e4",
   "metadata": {},
   "source": [
    "#### $ \\text{Prove Proposition } 3.3 \\text{ of the textbook. } $\n",
    "##### $ (\\text{Do not copy the proof from the textbook. You should write your own proof.}) $\n",
    "\n",
    "$ \\hspace{0.3cm}\\textbf{PROPOSITION } 3.3 \\; \\text{(Linearity of projection)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Suppose } \\mathcal{V} \\text{ is a closed linear subspace of } L^{2}( \\Omega{}, \\mathcal{F}, P ). $ \n",
    "\n",
    "$ \\hspace{0.3cm} X_{ 1 } \\text{ and } X_{ 2 } \\text{ are in } L^{2}( \\Omega{}, \\mathcal{F}, P ) \\text{, and } a_{ 1 } \\text{ and } a_{ 2 } \\text{ are constants. Then} $\n",
    "\n",
    "$$ \\Pi{}_{ \\mathcal{V} }( a_{ 1 } X_{ 1 } + a_{ 2 } X_{ 2 } ) = a_{ 1 } \\Pi_{ \\mathcal{V} }( X_{ 1 } ) + a_{ 2 } \\Pi_{ \\mathcal{V} }( X_{ 2 } ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bb217",
   "metadata": {},
   "source": [
    "#### **(solution)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58c964",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\text{Let } \\mathcal{V} \\subset{} L^{2}( \\Omega{}, \\mathcal{F}{}, P ) \\text{ be a closed linear subspace.} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Inner product } \\langle Y, Z \\rangle := \\mathbb{}{E}[ Y Z ]. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Decompose } X_{1}, X_{2} \\text{ by their projections} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{1} := \\Pi{}_{ \\mathcal{V} }( X_{1} ), \\;\\; Z_{2} := \\Pi{}_{ \\mathcal{V} }( X_{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{1} - Z_{1} \\perp{} \\mathcal{V}, \\;\\; X_{2} - Z_{2} \\perp{} \\mathcal{V} \\;\\; \\because{} \\text{orthogonality principle (Theorem } 3.2 \\text{)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X_{i} = Z_{i} + ( X_{i} - Z_{i} ), \\;\\; Z_{i} \\in{} \\mathcal{V}, \\;\\; \\langle X_{i} - Z_{i}, Z \\rangle = 0 \\;\\; \\forall{} Z \\in{} \\mathcal{V}, \\; i = 1, 2 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Projection of } a_{1} X_{1} + a_{2} X_{2} \\text{ via orthogonality} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X := a_{1} X_{1} + a_{2} X_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} W := a_{1} Z_{1} + a_{2} Z_{2} \\in{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - W = a_{1} ( X_{1} - Z_{1} ) + a_{2} ( X_{2} - Z_{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{For any } Z \\in{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\langle X - W, Z \\rangle = a_{1} \\langle X_{1} - Z_{1}, Z \\rangle + a_{2} \\langle X_{2} - Z_{2}, Z \\rangle $\n",
    "\n",
    "$ \\hspace{2.3cm} \\displaystyle{} = a_{1} \\cdot{} 0 + a_{2} \\cdot{} 0 = 0 \\;\\; \\because{} X_{i} - Z_{i} \\perp{} \\mathcal{V}, \\; Z \\in{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} W \\in{} \\mathcal{V}, \\;\\; X - W \\perp{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use characterization of projection} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y = \\Pi{}_{ \\mathcal{V} }( X ) \\iff \\big( Y \\in{} \\mathcal{V} \\text{ and } X - Y \\perp{} \\mathcal{V} \\big){} \\;\\; \\because{} \\text{Theorem } 3.2 \\text{(b)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} W \\in{} \\mathcal{V}, \\;\\; X - W \\perp{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} W = \\Pi{}_{ \\mathcal{V} }( X ) = \\Pi{}_{ \\mathcal{V} }( a_{1} X_{1} + a_{2} X_{2} ) = a_{1} Z_{1} + a_{2} Z_{2} = a_{1} \\Pi{}_{ \\mathcal{V} }( X_{1} ) + a_{2} \\Pi{}_{ \\mathcal{V} }( X_{2} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\Pi{}_{ \\mathcal{V} }( a_{1} X_{1} + a_{2} X_{2} ) = a_{1} \\Pi{}_{ \\mathcal{V} }( X_{1} ) + a_{2} \\Pi{}_{ \\mathcal{V} }( X_{2} ). $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e021650",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fd04a",
   "metadata": {},
   "source": [
    "> ## Q8-2. **Projection onto Nested Subspaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0207f2a",
   "metadata": {},
   "source": [
    "#### $ \\text{Prove Proposition } 3.4 \\text{ of the textbook. } $\n",
    "##### $ (\\text{Do not copy the proof from the textbook. You should write your own proof.}) $\n",
    "\n",
    "$ \\hspace{0.3cm}\\textbf{PROPOSITION } 3.4 \\; \\text{(Projections onto nested subspaces)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Suppose } \\mathcal{V}_{1} \\, \\text{ and } \\, \\mathcal{V}_{2} \\, \\text{ are closed linear subspaces of } \\, L^{2}( \\Omega{}, \\mathcal{F}, P ) \\, \\text{ such that } \\, \\mathcal{V}_{2} \\subset{} \\mathcal{V}_{1}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Then for any } X \\in{} L^{2}( \\Omega{}, \\mathcal{F}, P ), \\; \\Pi{}_{ \\mathcal{V}_{2} }( X ) = \\Pi{}_{ \\mathcal{V}_{2} } \\Pi{}_{ \\mathcal{V}_{1} }( X ). \\, \\text{ Furthermore,} $\n",
    "\n",
    "$$ \\mathbb{E}\\left[{} ( X - \\Pi{}_{ \\mathcal{V}_{2} }( X ) )^{2} \\right]{} = \\mathbb{E}\\left[{} ( X - \\Pi{}_{ \\mathcal{V}_{1} }( X ) )^{2} \\right]{} + \\mathbb{E}\\left[{} ( \\Pi{}_{ \\mathcal{V}_{1} }( X ) - \\Pi{}_{ \\mathcal{V}_{2} }( X ) )^{2} \\right]{} $$\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{In particular, } \\, \\mathbb{E}\\left[{} ( X - \\Pi{}_{ \\mathcal{V}_{2} }( X ) )^{2} \\right]{} \\ge{} \\mathbb{E}\\left[{} ( X - \\Pi{}_{ \\mathcal{V}_{1} }( X ) )^{2} \\right]{}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046c335",
   "metadata": {},
   "source": [
    "#### **(proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b30c4",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\text{Let } \\mathcal{V}{}_{2} \\subset{} \\mathcal{V}{}_{1} \\subset{} L^{2}( \\Omega{}, \\mathcal{F}{}, P ), \\;\\; Y_{1} := \\Pi{}_{ \\mathcal{V}{}_{1} }( X ), \\;\\; Y_{2} := \\Pi{}_{ \\mathcal{V}{}_{2} }( X ). $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Composition } \\Pi{}_{ \\mathcal{V}{}_{2} } \\Pi{}_{ \\mathcal{V}{}_{1} } : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{1} \\in{} \\mathcal{V}{}_{1}, \\;\\; X - Y_{1} \\perp{} \\mathcal{V}{}_{1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{2} \\in{} \\mathcal{V}{}_{2}, \\;\\; X - Y_{2} \\perp{} \\mathcal{V}{}_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } W := \\Pi{}_{ \\mathcal{V}{}_{2} }( Y_{1} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} W \\in{} \\mathcal{V}{}_{2}, \\;\\; Y_{1} - W \\perp{} \\mathcal{V}{}_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - W = ( X - Y_{1} ) + ( Y_{1} - W ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - Y_{1} \\perp{} \\mathcal{V}{}_{1} \\supset{} \\mathcal{V}{}_{2}, \\;\\; Y_{1} - W \\perp{} \\mathcal{V}{}_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X - W \\perp{} \\mathcal{V}{}_{2}, \\; W \\in{} \\mathcal{V}{}_{2} \\Rightarrow{} W = \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) = Y_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) = \\Pi{}_{ \\mathcal{V}{}_{2} }( Y_{1} ) = \\Pi{}_{ \\mathcal{V}{}_{2} } \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Error decomposition} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - Y_{2} = ( X - Y_{1} ) + ( Y_{1} - Y_{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X - Y_{1} \\perp{} \\mathcal{V}{}_{1}, \\;\\; Y_{1}, Y_{2} \\in{} \\mathcal{V}{}_{1} \\Rightarrow{} Y_{1} - Y_{2} \\in{} \\mathcal{V}{}_{1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\langle X - Y_{1}, Y_{1} - Y_{2} \\rangle = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\| X - Y_{2} \\|^{2} = \\| X - Y_{1} \\|^{2} + \\| Y_{1} - Y_{2} \\|^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ] = \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} ] + \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) - \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ] \\geq{} \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) = \\Pi{}_{ \\mathcal{V}{}_{2} } \\Pi{}_{ \\mathcal{V}{}_{1} }( X ), $\n",
    "\n",
    "$ \\hspace{0.75cm} \\displaystyle{} \\mathbb{}{E}\\big[ ( X - \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} \\big]{} = \\mathbb{}{E}\\big[ ( X - \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} \\big]{} + \\mathbb{}{E}\\big[ ( \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) - \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} \\big]{} \\geq{} \\mathbb{}{E}\\big[ ( X - \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} \\big]{}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ca9dd",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332bf8c",
   "metadata": {},
   "source": [
    "> ## Q8-3. **Projection onto Orthogonal Sum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7697e",
   "metadata": {},
   "source": [
    "#### $ \\text{Prove Proposition } 3.5 \\text{ of the textbook. } $\n",
    "##### $ (\\text{Do not copy the proof from the textbook. You should write your own proof.}) $\n",
    "\n",
    "$ \\hspace{0.3cm}\\textbf{PROPOSITION } 3.5 \\; \\text{(Projection onto the span of orthogonal subspaces)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Suppose } \\mathcal{V}_{1} \\text{ and } \\mathcal{V}_{2} \\text{ are closed linear subspaces of } \\, L^{2}( \\Omega{}, \\mathcal{F}, P ) \\, \\text{ such that } \\mathcal{V}_{1} \\perp{} \\mathcal{V}_{2}, \\text{ which means } \\, \\mathbb{E}[ Z_{ 1 } Z_{ 2 } ] = 0 \\text{ for any } Z_{ 1 } \\in{} \\mathcal{V}_{1} \\, \\text{ and } \\, Z_{ 2 } \\in{} \\mathcal{V}_{2}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{Let } \\mathcal{V} = \\mathcal{V}_{1} \\oplus{} \\mathcal{V}_{2} = \\{ Z_{ 1 } + Z_{ 2 } : Z_{ i } \\in{} \\mathcal{V}_{i} \\} \\text{ denote the span of } \\mathcal{V}_{1} \\text{ and } \\mathcal{V}_{2}. \\, \\text{ Then for any } X \\in{} L^{2}( \\Omega{}, \\mathcal{F}, P ), \\; \\Pi{}_{ \\mathcal{V} }( X ) = \\Pi{}_{ \\mathcal{V}_{1} }( X ) + \\Pi{}_{ \\mathcal{V}_{2} }( X ). $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{The minimum mean square error satisfies}: $\n",
    "\n",
    "$$ \\mathbb{E}\\left[ ( X - \\Pi{}_{ \\mathcal{V} }( X ) )^{2} \\right] = \\mathbb{E}[ X^{2} ] - \\mathbb{E}\\left[ ( \\Pi{}_{ \\mathcal{V}_{1} }( X ) )^{2} \\right] - \\mathbb{E}\\left[ ( \\Pi{}_{ \\mathcal{V}_{2} }( X ) )^{2} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6689a",
   "metadata": {},
   "source": [
    "#### **(proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2d47d",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\text{Let } \\mathcal{V}{}_{1}, \\mathcal{V}{}_{2} \\subset{} L^{2}( \\Omega{}, \\mathcal{F}{}, P ) \\text{ be closed linear subspaces with } \\mathcal{V}{}_{1} \\perp{} \\mathcal{V}{}_{2}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{and } \\mathcal{V} := \\mathcal{V}{}_{1} \\oplus{} \\mathcal{V}{}_{2} = \\{ Z_{1} + Z_{2} : Z_{i} \\in{} \\mathcal{V}{}_{i} \\}, \\;\\; \\text{Inner product } \\langle{} Y, Z \\rangle{} := \\mathbb{}{E}[ Y Z ]. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Form of the projection onto } \\mathcal{V} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{1} := \\Pi{}_{ \\mathcal{V}{}_{1} }( X ), \\;\\; Z_{2} := \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{1} \\in{} \\mathcal{V}{}_{1}, \\; X - Z_{1} \\perp{} \\mathcal{V}{}_{1}, \\;\\; Z_{2} \\in{} \\mathcal{V}{}_{2}, \\; X - Z_{2} \\perp{} \\mathcal{V}{}_{2} \\;\\; \\because{} \\text{Theorem } 3.2 \\text{ (b)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} W := Z_{1} + Z_{2} \\in{} \\mathcal{V} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Orthogonality of } X - W \\text{ to } \\mathcal{V}{}_{1}, \\mathcal{V}{}_{2} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } \\, U_{1} \\in{} \\mathcal{V}{}_{1}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\langle{} X - W, U_{1} \\rangle{} = \\langle{} X - Z_{1} - Z_{2}, U_{1} \\rangle{} = \\langle{} X - Z_{1}, U_{1} \\rangle{} - \\langle{} Z_{2}, U_{1} \\rangle{} = 0 - 0 = 0 \\;\\; \\because{} X - Z_{1} \\perp{} \\mathcal{V}{}_{1}, \\; Z_{2} \\in{} \\mathcal{V}{}_{2} \\perp{} \\mathcal{V}{}_{1}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } \\, U_{2} \\in{} \\mathcal{V}{}_{2}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\langle{} X - W, U_{2} \\rangle{} = \\langle{} X - Z_{1} - Z_{2}, U_{2} \\rangle{} = \\langle{} X - Z_{2}, U_{2} \\rangle{} - \\langle{} Z_{1}, U_{2} \\rangle{} = 0 - 0 = 0 \\;\\; \\because{} X - Z_{2} \\perp{} \\mathcal{V}{}_{2}, \\; Z_{1} \\in{} \\mathcal{V}{}_{1} \\perp{} \\mathcal{V}{}_{2}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } \\,Z = U_{1} + U_{2}, \\; U_{i} \\in{} \\mathcal{V}{}_{i}. $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\langle{} X - W, Z \\rangle{} = \\langle{} X - W, U_{1} + U_{2} \\rangle{} = \\langle{} X - W, U_{1} \\rangle{} + \\langle{} X - W, U_{2} \\rangle{} = 0 + 0 = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X - W \\perp{} \\mathcal{V}, \\; W \\in{} \\mathcal{V} \\Rightarrow{} W = \\Pi{}_{ \\mathcal{V} }( X ) \\;\\; \\because{} \\text{Theorem } 3.2 \\text{ (b)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\Pi{}_{ \\mathcal{V} }( X ) = \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) + \\Pi{}_{ \\mathcal{V}{}_{2} }( X ). $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{MMSE expression} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V} }( X ) )^{2} ] = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V} }( X ) )^{2} ] \\;\\; \\because{} \\text{Theorem } 3.2 \\text{ (c)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Pi{}_{ \\mathcal{V} }( X ) = Z_{1} + Z_{2}, \\;\\; Z_{1} \\in{} \\mathcal{V}{}_{1}, \\; Z_{2} \\in{} \\mathcal{V}{}_{2}, \\; \\mathcal{V}{}_{1} \\perp{} \\mathcal{V}{}_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}[ ( Z_{1} + Z_{2} )^{2} ] = \\mathbb{}{E}[ Z_{1}^{2} ] + 2 \\mathbb{}{E}[ Z_{1} Z_{2} ] + \\mathbb{}{E}[ Z_{2}^{2} ] = \\mathbb{}{E}[ Z_{1}^{2} ] + \\mathbb{}{E}[ Z_{2}^{2} ] \\;\\; \\because{} Z_{1} \\perp{} Z_{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V} }( X ) )^{2} ] = \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} ] + \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V} }( X ) )^{2} ] = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} ] - \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ] $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\Pi{}_{ \\mathcal{V} }( X ) = \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) + \\Pi{}_{ \\mathcal{V}{}_{2} }( X ), \\;\\; \\mathbb{}{E}[ ( X - \\Pi{}_{ \\mathcal{V} }( X ) )^{2} ] = \\mathbb{}{E}[ X^{2} ] - \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{1} }( X ) )^{2} ] - \\mathbb{}{E}[ ( \\Pi{}_{ \\mathcal{V}{}_{2} }( X ) )^{2} ]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cc742",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e1fdc",
   "metadata": {},
   "source": [
    "> ## Q9. **Bernoulli Renewal Age Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d2ec9",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } U = ( U_{k} : k \\in{} \\mathbb{Z} ) \\text{ be such that for some } p \\in{} ( 0, 1 ) \\text{ the random variables } U_{k} \\text{ are independent, } $ \n",
    "#### $ \\text{with each having the Bernoulli distribution with parameter } p \\text{. Interpret } U_{k} = 1 \\text{ to mean that} $ \n",
    "#### $ \\text{a renewal or replacement of some part takes place at time } k. \\, \\text{ For } k \\in{} \\mathbb{Z}, \\, \\text{ let} \\, X_{k} = \\min{} \\{ i \\ge{} 1 : U_{ k - i } = 1 \\} . $\n",
    "#### $ \\text{In words, } X_{k} \\, \\text{ is the time elapsed since the last renewal strictly before time } k. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e63ed",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{The process } X \\text{ is a time-homogeneous Markov process. Indicate a suitable state space,} $ \n",
    "#### $ \\text{and describe the one-step transition probabilities.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913ee46",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{State space and recursion} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} U = ( U_{k} : k \\in{} \\mathbb{}{Z} ), \\;\\; U_{k} \\sim{} \\text{Bern}(p), \\;\\; \\text{i.i.d.}, \\;\\; p \\in{} (0,1) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{k} = \\min{} \\{ i \\geq{} 1 : U_{k-i} = 1 \\} \\; \\Rightarrow{} \\; X_{k} \\in{} \\{ 1,2,3,\\cdots{} \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{k+1} = 1 \\text{ if } U_{k} = 1, \\;\\; X_{k+1} = X_{k} + 1 \\text{ if } U_{k} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X_{k+1} = \\begin{cases} 1, & \\text{if } \\, U_{k} = 1 \\\\ X_{k} + 1, & \\text{if } \\, U_{k} = 0 \\end{cases}, \\;\\; \\text{state space } S = \\{ 1,2,3,\\cdots{} \\} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{One-step transition probabilities} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} (X_{k+1} = 1 \\mid{} X_{k} = i ) = \\mathbb{P} (U_{k} = 1 ) = p $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} (X_{k+1} = i+1 \\mid{} X_{k} = i )= \\mathbb{P} (U_{k} = 0 ) = 1 - p $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} (X_{k+1} = j \\mid{} X_{k} = i ) = 0 \\;\\; \\text{if } j \\notin{} \\{ 1, i+1 \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} p_{i1}(1) = p, \\;\\; p_{i,i+1}(1) = 1 - p, \\;\\; p_{ij}(1) = 0 \\;\\; \\forall{} i \\in{} S, \\; j \\in{} S $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X \\text{ is a time-homogeneous Markov chain on } S = \\{ 1,2,\\cdots{} \\} \\text{ with } p_{i1}(1) = p, \\; p_{i,i+1}(1) = 1-p $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49effb6",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{Find the distribution of } \\, X_{k} \\text{ for } k \\text{ fixed.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b97485",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Characterize } \\{ X_{k} = r \\} \\, \\text{ using } \\, U\\text{-sequence} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{k} = r \\; \\Leftrightarrow{} \\; U_{k-1} = 0, U_{k-2} = 0, \\cdots{}, U_{k-r+1} = 0, U_{k-r} = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} ( X_{k} = r ) = \\mathbb{P} ( U_{k-r} = 1 ) \\prod_{j=1}^{r-1} \\mathbb{P} ( U_{k-j} = 0 ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} = p \\cdot{} (1-p)^{r-1} \\;\\; \\because{} \\{ U_{m} \\} \\overset{\\text{i.i.d}}{\\sim{}} \\text{Bern}(p) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{P} ( X_{k} = r ) = p (1-p)^{r-1}, \\;\\; r = 1,2,\\cdots{}, \\; \\text{independent of } k $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X_{k} \\sim{} \\text{Geom}(p) \\, \\text{ on } \\, \\{ 1,2,\\cdots{} \\} \\, \\text{ for every fixed } k $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67974f0",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{Is } X \\text{ a stationary random process? Explain.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee51186",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{One-dimensional marginals} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P}( X_{k} = r ) = p (1-p)^{r-1} \\;\\; \\forall{} k \\in{} \\mathbb{}{Z}, \\; r \\in{} \\{ 1,2,\\cdots{} \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{all one-dimensional distributions of } X \\text{ are identical} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Finite-dimensional distributions via shift of } U : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} U = ( U_{k} )_{k \\in{} \\mathbb{}{Z}} \\, \\text{ are i.i.d.} \\; \\Rightarrow{} \\; ( U_{k_{1}},\\cdots{},U_{k_{n}} ) \\overset{d}{=} ( U_{k_{1}+h},\\cdots{},U_{k_{n}+h} ) \\;\\; \\forall{} k_{i}, h $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{k} = \\min{} \\big({} \\{ i \\geq{} 1 : U_{k-i} = 1 \\} \\big){} \\, \\text{ is a measurable functional of } \\, ( U_{m} )_{m \\leq{} k-1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} ( X_{k_{1}},\\cdots{},X_{k_{n}} ) \\overset{d}{=} ( X_{k_{1}+h},\\cdots{},X_{k_{n}+h} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} X \\text{ is a strictly stationary random process} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4cb4d2",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\text{Find the } k\\text{-step transition probabilities } \\, p_{ i j }( k ) = \\mathbb{P} \\{ X_{ n + k } = j \\mid{} X_{ n } = i \\}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2cf20",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Case (i)} \\, 1 \\leq{} j \\leq{} k \\text{ (last renewal in } \\{ n,\\cdots{},n+k-1 \\} ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n+k} = j \\Leftrightarrow{} U_{n+k-j} = 1, \\;\\; U_{n+k-j+1} = \\cdots{} = U_{n+k-1} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} j \\leq{} k \\Rightarrow{} n+k-j \\geq{} n \\Rightarrow{} \\text{event depends only on } ( U_{n},\\cdots{},U_{n+k-1} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} (X_{n+k} = j \\mid{} X_{n} = i ) = \\mathbb{P} ( U_{n+k-j} = 1, U_{n+k-j+1} = \\cdots{} = U_{n+k-1} = 0 ) = p (1-p)^{j-1} \\;\\; \\because{} \\{ U_{m} \\} \\text{ i.i.d.} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} p_{ij}(k) = p (1-p)^{j-1}, \\;\\; 1 \\leq{} j \\leq{} k, \\;\\; \\forall{} i \\geq{} 1 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Case (ii) } \\, j > k \\text{ (no renewal in } \\{ n,\\cdots{},n+k-1 \\} ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} = i \\Leftrightarrow{} \\text{last renewal before } n \\text{ at time } n-i $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} U_{n} = \\cdots{} = U_{n+k-1} = 0 \\Rightarrow{} \\text{no new renewal in } [n,n+k-1] $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{last renewal before } n+k \\text{ still at } n-i \\Rightarrow{} X_{n+k} = k + i $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{P} \\{ U_{n} = \\cdots{} = U_{n+k-1} = 0 \\mid{} X_{n} = i \\} = (1-p)^{k} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} p_{i,\\,i+k}(k) = (1-p)^{k}, \\;\\; \\text{and } p_{ij}(k) = 0 \\text{ for } j > k, \\, j \\neq{} i+k $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} p_{ij}(k) = \\begin{cases} p (1-p)^{j-1}, & \\text{if } \\, 1 \\leq{} j \\leq{} k \\\\ (1-p)^{k}, & \\text{if } \\, j = i + k \\\\ 0, & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc73bc8",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605b259",
   "metadata": {},
   "source": [
    "> ## Q10. **Jump Chain and Sojourn Times**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca36f37",
   "metadata": {},
   "source": [
    "#### $ \\text{Prove Proposition } 4.9 \\text{ of the textbook. } $\n",
    "##### $ (\\text{Do not copy the proof from the textbook. You should write your own proof.}) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\textbf{PROPOSITION } 4.9 \\; \\text{Let } X = ( X( k ) : k \\in{} \\mathbb{Z}_{+} ) \\text{ be a time-homogeneous Markov process with one-step transition probability matrix } P. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(a) The jump process } X^{J} \\text{ is itself a time-homogeneous Markov process, and its one-step transition probabilities are given by } \\, p_{ i j }^{J} = \\dfrac{ p_{ i j } }{ 1 - p_{ i i } } $\n",
    "\n",
    "$ \\hspace{0.75cm} \\text{ for } \\, i \\neq{} j \\, \\text{ and } \\, p_{ i i }^{J} = 0, \\; i, j \\in{} S. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(b) Given } X( 0 ), \\; X^{J}( 1 ) \\, \\text{ is conditionally independent of } \\, T_{0}. $\n",
    "\n",
    "$ \\hspace{0.3cm} \\text{(c) Given } ( X^{J}( 0 ), \\cdots{}, X^{J}( n ) ) = ( j_{0}, \\cdots{}, j_{n} ), \\text{ the variables } \\, T_{0}, \\cdots{}, T_{n} \\, \\text{ are conditionally independent, } $\n",
    "\n",
    "$ \\hspace{0.75cm} \\text{and the conditional distribution of } \\, T_{ l } \\text{ is geometric with parameter } \\, p_{j_{l} j_{l} } : $\n",
    "\n",
    "$$ \\hspace{0.3cm} \\mathbb{P}( T_{ l } = k \\mid{} X^{J}( 0 ) = j_{0}, \\cdots{}, X^{J}( n ) = j_{n} ) = p_{j_{l}j_{l}}^{k - 1} ( 1 - p_{ j_{ l } j_{ l } } ), \\;\\; 0 \\le{} l \\le{} n, \\;\\; k \\ge{} 1. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50855d95",
   "metadata": {},
   "source": [
    "#### **(a-proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092cc8f",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{One-step transition of } X^{ J } \\text{ from } i \\text{ to } j \\neq{} i : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( 1 ) = j \\mid{} X^{ J }( 0 ) = i ) \\ = \\sum_{ k = 1 }^{ \\infty{} } \\mathbb{}{P}( X^{ J }( 1 ) = j, T_{ 0 } = k \\mid{} X( 0 ) = i ) $\n",
    "\n",
    "$ \\hspace{4.55cm} \\displaystyle{} = \\sum_{ k = 1 }^{ \\infty{} } \\mathbb{}{P}( X( 1 ) = i, \\cdots{}, X( k - 1 ) = i, X( k ) = j \\mid{} X( 0 ) = i ) $\n",
    "\n",
    "$ \\hspace{4.55cm} \\displaystyle{} = \\sum_{ k = 1 }^{ \\infty{} } p_{ i i }^{ k - 1 } p_{ i j } \\;\\; \\because{} \\text{Markov, time-homogeneous} $\n",
    "\n",
    "$ \\hspace{4.55cm} \\displaystyle{} = p_{ i j } \\sum_{ k = 0 }^{ \\infty{} } p_{ i i }^{ k } = \\frac{ p_{ i j } }{ 1 - p_{ i i } } \\;\\; \\text{for } i \\neq{} j $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} p^{ J }_{ i j } = \\mathbb{}{P}( X^{ J }( 1 ) = j \\mid{} X^{ J }( 0 ) = i ) = \\frac{ p_{ i j } }{ 1 - p_{ i i } }, \\;\\; i \\neq{} j $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{No self-jump} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X^{ J }( 1 ) \\neq{} X^{ J }( 0 ) \\; \\Rightarrow{} \\; p^{ J }_{ i i } = \\mathbb{}{P}( X^{ J }( 1 ) = i \\mid{} X^{ J }( 0 ) = i ) = 0 $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Markov and time-homogeneous property} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( n + 1 ) = j \\mid{} X^{ J }( 0 ), \\cdots{}, X^{ J }( n ) ) = \\mathbb{}{P}( X^{ J }( n + 1 ) = j \\mid{} X^{ J }( n ) = i ) = p^{ J }_{ i j } \\;\\; \\because{} \\text{same calculation with } X( k ) \\text{ starting from } i $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X^{ J } \\text{ is time-homogeneous Markov with transition matrix } P^{ J } = ( p^{ J }_{ i j } ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} p^{ J }_{ i j } = \\dfrac{ p_{ i j } }{ 1 - p_{ i i } } \\; ( i \\neq{} j ), \\; p^{ J }_{ i i } = 0. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0865719",
   "metadata": {},
   "source": [
    "#### **(b-proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0420022",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Joint law given } X( 0 ) = i \\text{ for } j \\neq{} i : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( 1 ) = j, T_{ 0 } = k \\mid{} X( 0 ) = i ) = \\mathbb{}{P}( X( 1 ) = i, \\cdots{}, X( k - 1 ) = i, X( k ) = j \\mid{} X( 0 ) = i ) $\n",
    "\n",
    "$ \\hspace{5.4cm} \\displaystyle{} = p_{ i i }^{ k - 1 } p_{ i j } $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Marginals given } X( 0 ) = i : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( T_{ 0 } = k \\mid{} X( 0 ) = i ) = p_{ i i }^{ k - 1 } ( 1 - p_{ i i } ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( 1 ) = j \\mid{} X( 0 ) = i ) = \\frac{ p_{ i j } }{ 1 - p_{ i i } } = p^{ J }_{ i j } $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Factorization} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( 1 ) = j, T_{ 0 } = k \\mid{} X( 0 ) = i ) = p_{ i i }^{ k - 1 } p_{ i j } $\n",
    "\n",
    "$ \\hspace{5.4cm} \\displaystyle{} = \\Big( \\frac{ p_{ i j } }{ 1 - p_{ i i } } \\Big){} \\Big( p_{ i i }^{ k - 1 } ( 1 - p_{ i i } ) \\Big){} $\n",
    "\n",
    "$ \\hspace{5.4cm} \\displaystyle{} = \\mathbb{}{P}( X^{ J }( 1 ) = j \\mid{} X( 0 ) = i ) \\, \\mathbb{}{P}( T_{ 0 } = k \\mid{} X( 0 ) = i ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X^{ J }( 1 ) \\text{ and } T_{ 0 } \\text{ are conditionally independent given } X( 0 ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{Given } X( 0 ), \\; X^{ J }( 1 ) \\perp{} T_{ 0 }. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06e68b",
   "metadata": {},
   "source": [
    "#### **(c-proof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7bf67",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Conditional pmf of a single } T_{ l } : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X^{ J }( l ) = j_{ l }, \\;\\; X^{ J }( l + 1 ) = j_{ l + 1 }, \\;\\; T_{ l } = k \\; \\Leftrightarrow{} \\; X( 0 ) = j_{ l }, \\; X( 1 ) = \\cdots{} = X( k - 1 ) = j_{ l }, \\; X( k ) = j_{ l + 1 } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( T_{ l } = k, X^{ J }( l + 1 ) = j_{ l + 1 } \\mid{} X^{ J }( l ) = j_{ l } ) = \\mathbb{}{P}( X( 1 ) = j_{ l }, \\cdots{}, X( k - 1 ) = j_{ l }, X( k ) = j_{ l + 1 } \\mid{} X( 0 ) = j_{ l } ) $\n",
    "\n",
    "$ \\hspace{3.5cm} \\displaystyle{} = p_{ j_{ l } j_{ l } }^{ k - 1 } p_{ j_{ l } j_{ l + 1 } } \\;\\; \\because{} X \\text{ is Markov and time-homogeneous} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X^{ J }( l + 1 ) = j_{ l + 1 } \\mid{} X^{ J }( l ) = j_{ l } ) = \\sum_{ m = 1 }^{ \\infty{} } \\mathbb{}{P}( T_{ l } = m, X^{ J }( l + 1 ) = j_{ l + 1 } \\mid{} X^{ J }( l ) = j_{ l } ) $\n",
    "\n",
    "$ \\hspace{5.4cm} \\displaystyle{} = \\sum_{ m = 1 }^{ \\infty{} } p_{ j_{ l } j_{ l } }^{ m - 1 } p_{ j_{ l } j_{ l + 1 } } = p_{ j_{ l } j_{ l + 1 } } \\sum_{ m = 0 }^{ \\infty{} } p_{ j_{ l } j_{ l } }^{ m } = \\frac{ p_{ j_{ l } j_{ l + 1 } } }{ 1 - p_{ j_{ l } j_{ l } } } $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( T_{ l } = k \\mid{} X^{ J }( l ) = j_{ l }, X^{ J }( l + 1 ) = j_{ l + 1 } ) = \\frac{ \\mathbb{}{P}( T_{ l } = k, X^{ J }( l + 1 ) = j_{ l + 1 } \\mid{} X^{ J }( l ) = j_{ l } ) }{ \\mathbb{}{P}( X^{ J }( l + 1 ) = j_{ l + 1 } \\mid{} X^{ J }( l ) = j_{ l } ) } $\n",
    "\n",
    "$ \\hspace{6.6cm} \\displaystyle{} = \\frac{ p_{ j_{ l } j_{ l } }^{ k - 1 } p_{ j_{ l } j_{ l + 1 } } }{ \\frac{ p_{ j_{ l } j_{ l + 1 } } }{ 1 - p_{ j_{ l } j_{ l } } } } = p_{ j_{ l } j_{ l } }^{ k - 1 } ( 1 - p_{ j_{ l } j_{ l } } ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} T_{ l } \\mid{} ( X^{ J }( l ) = j_{ l }, X^{ J }( l + 1 ) = j_{ l + 1 } ) \\text{ has pmf } p_{ j_{ l } j_{ l } }^{ k - 1 } ( 1 - p_{ j_{ l } j_{ l } } ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Joint conditional law of } ( T_{ 0 }, \\cdots{}, T_{ n } ) : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( T_{ 0 } = k_{ 0 }, \\cdots{}, T_{ n } = k_{ n } \\mid{} X^{ J }( 0 ) = j_{ 0 }, \\cdots{}, X^{ J }( n ) = j_{ n } ) = \\Big( \\prod_{ l = 0 }^{ n - 1 } \\mathbb{}{P}( T_{ l } = k_{ l } \\mid{} X^{ J }( l ) = j_{ l }, X^{ J }( l + 1 ) = j_{ l + 1 } ) \\Big){} \\mathbb{}{P}( T_{ n } = k_{ n } \\mid{} X^{ J }( n ) = j_{ n } ) \\;\\; \\because{} \\text{disjoint time blocks, Markov property of } X $\n",
    "\n",
    "$ \\hspace{8.65cm} \\displaystyle{} = \\Big( \\prod_{ l = 0 }^{ n - 1 } p_{ j_{ l } j_{ l } }^{ k_{ l } - 1 } ( 1 - p_{ j_{ l } j_{ l } } ) \\Big){} \\, p_{ j_{ n } j_{ n } }^{ k_{ n } - 1 } ( 1 - p_{ j_{ n } j_{ n } } ) $\n",
    "\n",
    "$ \\hspace{8.6cm} \\displaystyle{} = \\prod_{ l = 0 }^{ n } p_{ j_{ l } j_{ l } }^{ k_{ l } - 1 } ( 1 - p_{ j_{ l } j_{ l } } ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{}{P}( T_{ 0 } = k_{ 0 }, \\cdots{}, T_{ n } = k_{ n } \\mid{} X^{ J }( 0 ) = j_{ 0 }, \\cdots{}, X^{ J }( n ) = j_{ n } ) = \\prod_{ l = 0 }^{ n } \\mathbb{}{P}( T_{ l } = k_{ l } \\mid{} X^{ J }( 0 ) = j_{ 0 }, \\cdots{}, X^{ J }( n ) = j_{ n } ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} T_{ 0 }, \\cdots{}, T_{ n } \\, \\text{ are conditionally independent given } ( X^{ J }( 0 ), \\cdots{}, X^{ J }( n ) ), $\n",
    "\n",
    "$ \\hspace{0.75cm} \\displaystyle{} \\text{and } \\mathbb{}{P}( T_{ l } = k \\mid{} X^{ J }( 0 ) = j_{ 0 }, \\cdots{}, X^{ J }( n ) = j_{ n } ) = p_{ j_{ l } j_{ l } }^{ k - 1 } ( 1 - p_{ j_{ l } j_{ l } } ). $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4737531",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01521e7",
   "metadata": {},
   "source": [
    "> ## Q11. **Simulation of a $3$-State Markov Chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43bb1e",
   "metadata": {},
   "source": [
    "#### $ \\text{Consider the following Markov chain} $\n",
    "#### <p align=\"center\"> <img src=\"../img/00.3. Final-Exam (1).png\" width=\"35%\" height=\"35%\"></img> </p>\n",
    "#### $ \\text{Use MATLAB or Python to solve the following problem} $\n",
    "#### $ \\text{With time sample } 0.01 \\text{, generate a sample path of the Markov chain from time } 0 \\text{ to } 2 $\n",
    "#### $ \\text{Compute the following using MATLAB or Python (for any } k \\ge{} 0 ), $\n",
    "#### $ \\text{and try to compare them with analytic results (theoretical computation).} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc750194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# 0. imports library\n",
    "import numpy as np\n",
    "\n",
    "# ===========================================================================\n",
    "# 1. define variabels\n",
    "## (1) seed-number\n",
    "seed = 2025\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "## (2) states\n",
    "A, B, C = 0, 1, 2                           # states encoding\n",
    "states = np.array(object=[A, B, C])         # states index set\n",
    "\n",
    "## (3) transition matrix\n",
    "P = np.array(\n",
    "    object=[\n",
    "        [0.65, 0.25, 0.10],                 # from A\n",
    "        [0.40, 0.40, 0.20],                 # from B\n",
    "        [0.50, 0.30, 0.20],                 # from C\n",
    "    ],\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "# ===========================================================================\n",
    "# 2. define simulation parameters\n",
    "## (1) time-grid\n",
    "dt = 0.01\n",
    "T = 2\n",
    "n_steps = int(T / dt)\n",
    "t_grid = np.linspace(start=0.0, stop=T, num=n_steps + 1)\n",
    "x = np.zeros(shape=(n_steps + 1,), dtype=int)\n",
    "\n",
    "## (2) initial state\n",
    "x[0] = A  \n",
    "\n",
    "# ===========================================================================\n",
    "# 3. sample path generation (Markov chain simulation)\n",
    "for k in range(n_steps):\n",
    "    s = x[k]\n",
    "    x[k + 1] = rng.choice(a=states, p=P[s])\n",
    "\n",
    "# ===========================================================================\n",
    "# 4. computation conditional probabilities and expected values\n",
    "## (0) user-defined function\n",
    "def cond_prob_next_A(idx:np.array) -> float :\n",
    "    if idx.size == 0 :\n",
    "        return np.nan\n",
    "    next_state = x[idx + 1]\n",
    "    return np.mean(next_state == A)\n",
    "\n",
    "## (Q11-a) P(X_{k+1} = A | X_{k} = B)\n",
    "idx_a = np.where((x[:-1] == B))[0]\n",
    "prob_a_emp = cond_prob_next_A(idx=idx_a)\n",
    "\n",
    "## (Q11-b) P(X_{k+1} = A | X_{k} = B, X_{k-1} = C)\n",
    "idx_b = np.where(((x[1:-1] == B) & (x[:-2] == C)))[0] + 1\n",
    "prob_b_emp = cond_prob_next_A(idx=idx_b)\n",
    "\n",
    "## (Q11-c) P(X_{k+1} = A | X_{k} = B, X_{k-1} = C, X_{k-2} = B)\n",
    "idx_c = np.where(((x[2:-1] == B) & (x[1:-2] == C) & (x[:-3] == B)))[0] + 2\n",
    "prob_c_emp = cond_prob_next_A(idx=idx_c)\n",
    "\n",
    "## (Q11-d~e) E[1_{X_{k+1}=A} | ...]\n",
    "p_theory = P[B, A]        # theoretical P(X_{k+1} = A | X_{k} = B)\n",
    "E_d_emp = prob_a_emp      # E[1_{X_{k+1}=A} | X_{k} = B]\n",
    "E_e_emp = prob_b_emp      # E[1_{X_{k+1}=A} | X_{k} = B, X_{k-1} = C]\n",
    "E_f_emp = prob_c_emp      # E[1_{X_{k+1}=A} | X_{k} = B, X_{k-1} = C, X_{k-2} = B]\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80371d",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\mathbb{P}( X_{ k+1 } = A \\mid{} X_{ k } = B ) $\n",
    "##### $ \\text{(probability that the chain visits state } A \\text{ given current state } B ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c50c6d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) P_hat = 0.3559\n",
      "    P_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(a) P_hat = {prob_a_emp:.4f}\\n    P_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69d03e",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\mathbb{P}( X_{ k+1 } = A \\mid{} X_{ k } = B, X_{ k-1 } = C ) $\n",
    "##### $ \\text{(probability that the chain visits state } A \\text{ given current state } B \\text{ and previous state } C ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba643f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b) P_hat = 0.3750\n",
      "    P_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(b) P_hat = {prob_b_emp:.4f}\\n    P_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdba6a2",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\mathbb{P}( X_{ k+1 } = A \\mid{} X_{ k } = B, X_{ k-1 } = C, X_{ k-2 } = B ) $\n",
    "##### $ \\text{(probability that the chain visits state } A \\text{ given current state } B \\text{ and previous states } C \\text{ and } B ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cf025ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c) P_hat = 0.3333\n",
      "    P_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(c) P_hat = {prob_c_emp:.4f}\\n    P_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a829ce3",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\mathbb{E}[ X_{ k+1 } = A \\mid{} X_{ k } = B ] $\n",
    "##### $ \\text{(expected value that the chain visits state } A \\text{ given current state } B ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e04696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d) E_hat = 0.3559\n",
      "    E_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(d) E_hat = {E_d_emp:.4f}\\n    E_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1b612",
   "metadata": {},
   "source": [
    "#### **(e)** $ \\mathbb{E}[ X_{ k+1 } = A \\mid{} X_{ k } = B, X_{ k-1 } = C ] $\n",
    "##### $ \\text{(expected value that the chain visits state } A \\text{ given current state } B \\text{ and previous state } C ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2af6dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(e) E_hat = 0.3750\n",
      "    E_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(e) E_hat = {E_e_emp:.4f}\\n    E_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b67d70",
   "metadata": {},
   "source": [
    "#### **(f)** $ \\mathbb{E}[ X_{ k+1 } = A \\mid{} X_{ k } = B, X_{ k-1 } = C, X_{ k-2 } = B ] $\n",
    "##### $ \\text{(expected value that the chain visits state } A \\text{ given current state } B \\text{ and previous states } C \\text{ and } B ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9680df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(f) E_hat = 0.3333\n",
      "    E_theory = 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"(f) E_hat = {E_f_emp:.4f}\\n    E_theory = {p_theory:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad8a89",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5726a",
   "metadata": {},
   "source": [
    "> ## Q12. **Nonlinear Transforms: Markov, Stationarity, Martingale**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a0d3b",
   "metadata": {},
   "source": [
    "#### $ \\text{Let } X = ( X_{ n } : n \\in \\mathbb{Z} ), \\; Y = ( Y_{ n } : n \\in \\mathbb{Z} ), \\; Z = ( Z_{ n } : n \\in \\mathbb{Z} ) \\text{ be random processes such that } $ \n",
    "#### $ Y_{ n } = X_{ n }^{2} \\, \\text{ for all } \\, n \\, \\text{ and } \\, Z_{ n } = X_{ n }^{3} \\, \\text{ for all } \\, n. $\n",
    "#### $ \\text{Determine whether each of the following statements is always true. If true, give a justification.} $ \n",
    "#### $ \\text{If not, give a simple counter example.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d404ee6",
   "metadata": {},
   "source": [
    "#### **(a)** $ \\text{If } X \\text{ is Markov then } Y \\text{ is Markov.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c7eeb",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Construct a Markov chain } X \\text{ such that } Y_{n} = X_{n}^{2} \\text{ is not Markov} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} S_{X} = \\{ -1, 1, 2 \\}, \\;\\; Y_{n} = X_{n}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} -1 \\mapsto{} -1, \\;\\; 1 \\mapsto{} 2, \\;\\; 2 \\mapsto{} 1 \\;\\; \\text{(deterministic transitions)} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X_{0} = -1 ) = \\mathbb{}{P}( X_{0} = 2 ) = \\tfrac{1}{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} X \\text{ is a timeâ€“homogeneous Markov chain}, \\;\\; Y_{n} \\in{} \\{ 1, 4 \\}, \\;\\; 1 = (-1)^{2} = 1^{2}, \\;\\; 4 = 2^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{0} = -1 \\Rightarrow{} X_{1} = -1 \\Rightarrow{} X_{2} = -1 \\Rightarrow{} ( Y_{0}, Y_{1}, Y_{2} ) = ( 1, 1, 1 ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{0} = 2 \\Rightarrow{} X_{1} = 1 \\Rightarrow{} X_{2} = 2 \\Rightarrow{} ( Y_{0}, Y_{1}, Y_{2} ) = ( 4, 1, 4 ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( Y_{2} = 4 \\mid{} Y_{1} = 1, Y_{0} = 1 ) = 0, \\;\\; \\mathbb{}{P}( Y_{2} = 4 \\mid{} Y_{1} = 1, Y_{0} = 4 ) = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( Y_{0} = 1 \\mid{} Y_{1} = 1 ) = \\mathbb{}{P}( Y_{0} = 4 \\mid{} Y_{1} = 1 ) = \\tfrac{1}{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{P}( Y_{2} = 4 \\mid{} Y_{1} = 1 ) = \\tfrac{1}{2} \\neq{} \\mathbb{}{P}( Y_{2} = 4 \\mid{} Y_{1} = 1, Y_{0} = 1 ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Y \\text{ does not satisfy the Markov property while } X \\text{ is Markov} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(a) is not always true. (False)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db10f8",
   "metadata": {},
   "source": [
    "#### **(b)** $ \\text{If } X \\text{ is Markov then } Z \\text{ is Markov.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0cba5",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use a bijective pointwise transform } \\phi{}(x) = x^{3} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{n} = X_{n}^{3}, \\;\\; \\phi{} : \\mathbb{}{R} \\to{} \\mathbb{}{R}, \\;\\; \\phi{}(x) = x^{3}, \\;\\; \\phi{}^{-1}(z) = z^{1/3} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\sigma{}( Z_{0}, \\cdots{}, Z_{n} ) = \\sigma{}( \\phi{}( X_{0} ), \\cdots{}, \\phi{}( X_{n} ) ) = \\sigma{}( X_{0}, \\cdots{}, X_{n} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } B \\subseteq{} \\mathbb{}{R} \\text{ be Borel and } A = \\phi{}^{-1}( B ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\{ Z_{n+1} \\in{} B \\} = \\{ X_{n+1}^{3} \\in{} B \\} = \\{ X_{n+1} \\in{} A \\} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}\\big( Z_{n+1} \\in{} B \\mid{} Z_{0}, \\cdots{}, Z_{n} \\big) = \\mathbb{}{P}\\big( X_{n+1} \\in{} A \\mid{} X_{0}, \\cdots{}, X_{n} \\big) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{If } X \\text{ is Markov, } \\mathbb{}{P}\\big( X_{n+1} \\in{} A \\mid{} X_{0}, \\cdots{}, X_{n} \\big) = \\mathbb{}{P}\\big( X_{n+1} \\in{} A \\mid{} X_{n} \\big) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{P}\\big( Z_{n+1} \\in{} B \\mid{} Z_{0}, \\cdots{}, Z_{n} \\big) = \\mathbb{}{P}\\big( X_{n+1} \\in{} A \\mid{} X_{n} \\big) = \\mathbb{}{P}\\big( Z_{n+1} \\in{} B \\mid{} Z_{n} \\big) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Z \\text{ satisfies the Markov property whenever } X \\text{ does} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(b) is always true. (True)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fd948",
   "metadata": {},
   "source": [
    "#### **(c)** $ \\text{If } Y \\text{ is Markov then } X \\text{ is Markov.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a5575",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Construct } X \\text{ nonâ€“Markov with } Y_{n} = X_{n}^{2} \\text{ trivial Markov} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} S_{X} = \\{ -1, 1 \\}, \\;\\; Y_{n} = X_{n}^{2} \\equiv{} 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( ( X_{0}, X_{1} ) = ( -1, 1 ) ) = \\mathbb{}{P}( ( X_{0}, X_{1} ) = ( 1, -1 ) ) = \\tfrac{1}{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{For } n \\geq{} 1, \\;\\; X_{n+1} = X_{n-1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} X_{2} = X_{0}, \\;\\; X_{3} = X_{1}, \\;\\; \\cdots{} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X_{2} = 1 \\mid{} X_{1} = 1, X_{0} = 1 ) = 1, \\;\\; \\mathbb{}{P}( X_{2} = 1 \\mid{} X_{1} = 1, X_{0} = -1 ) = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{P}( X_{2} = 1 \\mid{} X_{1} = 1 ) \\text{ depends on } X_{0} \\Rightarrow{} X \\text{ is not Markov} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{n} \\equiv{} 1 \\Rightarrow{} \\mathbb{}{P}( Y_{n+1} = 1 \\mid{} Y_{0}, \\cdots{}, Y_{n} ) = 1 \\;\\; \\forall{} n $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Y \\text{ is a Markov chain while } X \\text{ is not Markov} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(c) is not always true. (False)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18197853",
   "metadata": {},
   "source": [
    "#### **(d)** $ \\text{If } X \\text{ is stationary then } Y \\text{ is stationary.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87310dc5",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use stationarity and a pointwise transform } g(x) = x^{2} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X = ( X_{n} )_{ n \\in{} \\mathbb{}{Z} } \\text{ strictly stationary} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( X_{n_{1}}, \\cdots{}, X_{n_{k}} ) \\overset{d}{=} ( X_{n_{1}+h}, \\cdots{}, X_{n_{k}+h} ) \\;\\; \\forall{} n_{1}, \\cdots{}, n_{k}, h \\in{} \\mathbb{}{Z} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Y_{n} = g( X_{n} ), \\;\\; g(x) = x^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( Y_{n_{1}}, \\cdots{}, Y_{n_{k}} ) = ( g( X_{n_{1}} ), \\cdots{}, g( X_{n_{k}} ) ) \\overset{d}{=} ( g( X_{n_{1}+h} ), \\cdots{}, g( X_{n_{k}+h} ) ) = ( Y_{n_{1}+h}, \\cdots{}, Y_{n_{k}+h} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Y \\text{ is strictly stationary whenever } X \\text{ is strictly stationary} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(d) is always true. (True)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205baf3",
   "metadata": {},
   "source": [
    "#### **(e)** $ \\text{If } Y \\text{ is stationary then } X \\text{ is stationary.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e577b2",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Define } X, Y \\text{ by a timeâ€“asymmetric sign flip} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Let } A > 0 \\text{ be a nonâ€“degenerate random variable} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} = \\begin{cases} A, & n \\geq{} 0 \\\\ -A, & n < 0 \\end{cases}, \\;\\; Y_{n} = X_{n}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Y_{n} = A^{2} \\;\\; \\forall{} n \\in{} \\mathbb{}{Z} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Check stationarity of } Y : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{For any } k \\geq{} 1, \\; n_{1}, \\cdots{}, n_{k} \\in{} \\mathbb{}{Z}, \\; h \\in{} \\mathbb{}{Z} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( Y_{n_{1}}, \\cdots{}, Y_{n_{k}} ) = ( A^{2}, \\cdots{}, A^{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( Y_{n_{1}+h}, \\cdots{}, Y_{n_{k}+h} ) = ( A^{2}, \\cdots{}, A^{2} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} ( Y_{n_{1}}, \\cdots{}, Y_{n_{k}} ) \\overset{d}{=} ( Y_{n_{1}+h}, \\cdots{}, Y_{n_{k}+h} ) \\;\\; \\forall{} n_{i}, h $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compare oneâ€“dimensional distributions of } X : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{0} = A, \\;\\; X_{-1} = -A $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{P}( X_{0} \\in{} B ) = \\mathbb{}{P}( A \\in{} B ), \\;\\; \\mathbb{}{P}( X_{-1} \\in{} B ) = \\mathbb{}{P}( -A \\in{} B ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Choose a Borel set } B \\subseteq{} \\mathbb{}{R} \\text{ such that } \\mathbb{}{P}( A \\in{} B ) \\neq{} \\mathbb{}{P}( -A \\in{} B ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\mathbb{}{P}( X_{0} \\in{} B ) \\neq{} \\mathbb{}{P}( X_{-1} \\in{} B ) \\;\\; \\Rightarrow{} \\;\\; X_{0}, X_{-1} \\text{ have different distributions} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(e) is not always true. (False)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53d497",
   "metadata": {},
   "source": [
    "#### **(f)** $ \\text{If } X \\text{ is wide sense stationary then } Y \\text{ is wide sense stationary.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f403dc",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Define } X \\text{ with even/odd marginals but same second order moments} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} \\text{ independent over } n $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} n \\text{ even } \\Rightarrow{} X_{n} = \\begin{cases} 1, & \\tfrac{1}{2} \\\\ -1, & \\tfrac{1}{2} \\end{cases} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{E}( X_{n} ) = 0, \\;\\; \\mathbb{}{E}( X_{n}^{2} ) = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} n \\text{ odd } \\Rightarrow{} X_{n} = 2 \\text{ with prob. } \\tfrac{1}{8}, \\; -2 \\text{ with prob. } \\tfrac{1}{8}, \\; 0 \\text{ with prob. } \\tfrac{3}{4} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{E}( X_{n} ) = 0, \\;\\; \\mathbb{}{E}( X_{n}^{2} ) = 4 \\cdot{} \\tfrac{1}{4} = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Independence } \\Rightarrow{} \\text{Cov}( X_{n}, X_{m} ) = 0 \\text{ for } n \\neq{} m $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{Var}( X_{n} ) = 1 \\;\\; \\forall{} n, \\;\\; \\text{Cov}( X_{n}, X_{n+k} ) = \\begin{cases} 1, & k = 0 \\\\ 0, & k \\neq{} 0 \\end{cases} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X \\text{ is wide sense stationary} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Compute second order structure of } Y_{n} = X_{n}^{2} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} n \\text{ even } \\Rightarrow{} Y_{n} = 1 \\;\\; \\text{a.s.} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{E}( Y_{n} ) = 1, \\;\\; \\mathbb{}{E}( Y_{n}^{2} ) = 1, \\;\\; \\text{Var}( Y_{n} ) = 1 - 1^{2} = 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} n \\text{ odd } \\Rightarrow{} Y_{n} = 4 \\text{ with prob. } \\tfrac{1}{4}, \\; 0 \\text{ with prob. } \\tfrac{3}{4} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rightarrow{} \\mathbb{}{E}( Y_{n} ) = 4 \\cdot{} \\tfrac{1}{4} = 1 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}( Y_{n}^{2} ) = 16 \\cdot{} \\tfrac{1}{4} = 4, \\;\\; \\text{Var}( Y_{n} ) = 4 - 1^{2} = 3 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{Var}( Y_{n} ) = 0 \\text{ for even } n, \\;\\; \\text{Var}( Y_{n} ) = 3 \\text{ for odd } n $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\text{Cov}( Y_{n}, Y_{n} ) \\text{ depends on } n \\text{ (not only on the lag } 0 \\text{)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(f) is not always true. (False)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e549218",
   "metadata": {},
   "source": [
    "#### **(g)** $ \\text{If } X \\text{ has independent increments then } Y \\text{ has independent increments.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf7ee5",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Take a simple process with independent increments} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} = \\sum_{k=1}^{n} \\varepsilon{}_{k}, \\;\\; n \\geq{} 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\varepsilon{}_{k} \\text{ i.i.d., } \\mathbb{}{P}( \\varepsilon{}_{k} = 1 ) = \\mathbb{}{P}( \\varepsilon{}_{k} = -1 ) = \\tfrac{1}{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Delta{} X_{n} := X_{n} - X_{n-1} = \\varepsilon{}_{n} \\;\\; \\text{independent over } n $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} X \\text{ has independent increments} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Express increments of } Y_{n} = X_{n}^{2} \\text{ in terms of shared noise} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Delta{} Y_{n} := Y_{n} - Y_{n-1} = X_{n}^{2} - X_{n-1}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} = X_{n-1} + \\varepsilon{}_{n} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Delta{} Y_{n} = ( X_{n-1} + \\varepsilon{}_{n} )^{2} - X_{n-1}^{2} = 2 X_{n-1} \\varepsilon{}_{n} + \\varepsilon{}_{n}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Delta{} Y_{n+1} = X_{n+1}^{2} - X_{n}^{2} = ( X_{n} + \\varepsilon{}_{n+1} )^{2} - X_{n}^{2}  = 2 X_{n} \\varepsilon{}_{n+1} + \\varepsilon{}_{n+1}^{2} = 2 ( X_{n-1} + \\varepsilon{}_{n} ) \\varepsilon{}_{n+1} + \\varepsilon{}_{n+1}^{2} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\Delta{} Y_{n} = F( X_{n-1}, \\varepsilon{}_{n} ), \\;\\; \\Delta{} Y_{n+1} = G( X_{n-1}, \\varepsilon{}_{n}, \\varepsilon{}_{n+1} ) $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use shared randomness to see dependence} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} ( X_{n-1}, \\varepsilon{}_{n} ) \\text{ is nonâ€“degenerate and appears in both } \\Delta{} Y_{n}, \\Delta{} Y_{n+1} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\text{Hence } \\sigma{}( \\Delta{} Y_{n} ) \\text{ and } \\sigma{}( \\Delta{} Y_{n+1} ) \\text{ both contain information on } ( X_{n-1}, \\varepsilon{}_{n} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} \\Delta{} Y_{n} \\text{ and } \\Delta{} Y_{n+1} \\text{ cannot be independent (unless } X_{n-1}, \\varepsilon{}_{n} \\text{ degenerate)} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(g) is not always true. (False)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21c94a",
   "metadata": {},
   "source": [
    "#### **(h)** $ \\text{If } X \\text{ is a martingale then } Z \\text{ is a martingale.} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347814d",
   "metadata": {},
   "source": [
    "$ \\hspace{0.3cm} \\displaystyle{} \\cdot{} \\, \\text{Use the same symmetric random walk and take } Z_{n} = X_{n}^{3} : $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n} = \\sum_{k=1}^{n} \\varepsilon{}_{k}, \\;\\; \\varepsilon{}_{k} \\text{ as above}, \\;\\; \\mathcal{F}{}_{n} = \\sigma{}( \\varepsilon{}_{1}, \\cdots{}, \\varepsilon{}_{n} ) $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}( \\varepsilon{}_{n+1} \\mid{} \\mathcal{F}{}_{n} ) = 0 \\Rightarrow{} \\mathbb{}{E}( X_{n+1} \\mid{} \\mathcal{F}{}_{n} ) = X_{n} \\Rightarrow{} X \\text{ is a martingale} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} Z_{n} = X_{n}^{3} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} X_{n+1} = X_{n} + \\varepsilon{}_{n+1} \\Rightarrow{} Z_{n+1} = ( X_{n} + \\varepsilon{}_{n+1} )^{3} $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\mathbb{}{E}( Z_{n+1} \\mid{} \\mathcal{F}{}_{n} ) = \\mathbb{}{E}( ( X_{n} + \\varepsilon{}_{n+1} )^{3} \\mid{} \\mathcal{F}{}_{n} ) $\n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} = X_{n}^{3} + 3 X_{n}^{2} \\mathbb{}{E}( \\varepsilon{}_{n+1} \\mid{} \\mathcal{F}{}_{n} ) + 3 X_{n} \\mathbb{}{E}( \\varepsilon{}_{n+1}^{2} \\mid{} \\mathcal{F}{}_{n} ) + \\mathbb{}{E}( \\varepsilon{}_{n+1}^{3} \\mid{} \\mathcal{F}{}_{n} ) $\n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} = X_{n}^{3} + 3 X_{n} \\;\\; \\because{} \\mathbb{}{E}( \\varepsilon{}_{n+1} ) = 0, \\; \\mathbb{}{E}( \\varepsilon{}_{n+1}^{2} ) = 1, \\; \\mathbb{}{E}( \\varepsilon{}_{n+1}^{3} ) = 0 $\n",
    "\n",
    "$ \\hspace{2.5cm} \\displaystyle{} \\neq{} X_{n}^{3} = Z_{n} \\;\\; \\text{with positive probability since } X_{n} \\not\\equiv{} 0 $\n",
    "\n",
    "$ \\hspace{0.45cm} \\displaystyle{} \\Rrightarrow{} Z \\text{ does not satisfy the martingale property even though } X \\text{ is a martingale} $\n",
    "\n",
    "$ \\hspace{0.3cm} \\displaystyle{} \\therefore{} \\text{(h) is not always true. (False)} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
