{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbd15f2",
   "metadata": {},
   "source": [
    "# CH05.3. **MMSE estimator Type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3bae9",
   "metadata": {},
   "source": [
    "> ## **자명 추정기(Trivial estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6efca",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 확률 벡터 $ \\textbf{Y} $가 (닫힌 선형) 부분공간 $ \\mathcal{V} $ 안에 포함되는 경우로 정의된 추정기\n",
    "#### $ = $ 확률 벡터 $ \\textbf{Y} $가 부분공간 $ \\mathcal{V} $ 안에 존재하는 경우로 정의된 MSE 최소화 문제\n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\displaystyle{} \\argmin_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} $ \n",
    "#### $ \\hspace{0.45cm} \\text{s.t. } \\, \\textbf{Y} \\in{} \\mathcal{V}, \\;\\; \\text{ where } \\, \\mathcal{V} \\subset{} L^{2}(\\Omega{};\\mathbb{R}^{m}) \\, \\text{ is closed subspace}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24423569",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 유클리드 공간에서의 시각화\n",
    "##### $ \\hspace{0.15cm} $ <img src=\"../img/01.3. MMSE estimator analysis (1).png\" align=\"center\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347de08",
   "metadata": {},
   "source": [
    "#### **(2) 최적해** : \n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\textbf{Y} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a585c04",
   "metadata": {},
   "source": [
    "#### **(3) 최소값** : \n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\mathbb{E}[\\|\\textbf{Y}-\\hat{\\textbf{Y}}^{*}\\|^{2}_{2}] = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf0652",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052678c",
   "metadata": {},
   "source": [
    "> ## **상수 추정기(Constant estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d9a6d",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 확률 벡터 $ \\textbf{Y} $에 대한 추정기 $ \\hat{\\textbf{Y}} $를 하나의 상수 벡터로 제한한 경우로 정의된 추정기\n",
    "#### $ = $ 부분공간 $ \\mathcal{V} $를 ($ L^{2} $ 공간 안의) 상수 함수(벡터) $ \\textbf{c} $들로 제한한 MSE 최소화 문제\n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\displaystyle{} \\argmin_{\\hat{\\textbf{Y}}\\in{}\\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\argmin_{\\textbf{c}\\in{}\\mathbb{R}^{m}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\textbf{c}\\|^{2}_{2}\\big]{} $ \n",
    "#### $ \\hspace{0.45cm} \\text{where } \\, \\mathcal{V} := \\{ \\hat{\\textbf{Y}} \\in{} L^{2}(\\Omega{};\\mathbb{R}^{m}) \\mid{} \\hat{\\textbf{Y}} = \\textbf{c}, \\;\\; \\textbf{c} \\in{} \\mathbb{R}^{m} \\}, \\;\\; \\mathcal{V} \\, \\text{ is closed subspace}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44363582",
   "metadata": {},
   "source": [
    "#### **(2) 최적해** : \n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\mathbb{E}[\\textbf{Y}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488bfc8",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** \n",
    "##### $ \\hspace{0.15cm} \\text{method 1. vector differentiation} $\n",
    "##### $ \\hspace{0.3cm} \\text{define } \\, f(\\textbf{c}) = \\mathbb{E}[\\| \\textbf{Y} - \\textbf{c} \\|^{2}_{2}] \\;\\; \\text{ where } \\, \\hat{\\textbf{Y}} = \\textbf{c} \\in{} \\mathcal{V} \\subset{} \\mathbb{R}^{m} $\n",
    "##### $ \\hspace{0.3cm} \\nabla{}_{\\textbf{c}}f(\\textbf{c}) = \\frac{\\mathrm{d}}{\\mathrm{d}\\textbf{c}}\\bigg({}\\mathbb{E}[\\textbf{Y}^{T}\\textbf{Y}]-2\\textbf{c}^{T}\\mathbb{E}[\\textbf{Y}] + \\textbf{c}^{T}\\textbf{c} \\bigg){} $\n",
    "##### $ \\hspace{1.5cm} = -2 \\mathbb{E}[\\textbf{Y}] + 2 \\textbf{c} = \\textbf{0} $\n",
    "##### $ \\hspace{0.3cm} \\therefore{} \\textbf{c}^{*} = \\hat{\\textbf{Y}}^{*} = \\mathbb{E}[\\textbf{Y}] \\;\\; \\because{} f^{''}(\\textbf{c}) = 2I > 0 \\;\\; (\\text{convex function}) $\n",
    "##### $ \\hspace{0.15cm} \\text{method 2. orthogonality principle} $\n",
    "##### $ \\hspace{0.3cm} \\text{define } \\, \\textbf{c} \\in{} \\mathcal{V} = \\text{span} \\big({} \\{ \\textbf{e}_{1}, \\textbf{e}_{2}, \\cdots{}, \\textbf{e}_{m} \\} \\big){} \\subset{} \\mathbb{R}^{m}, \\;\\; \\textbf{e}_{i} \\, \\text{ is standard basis vector}. $\n",
    "##### $ \\hspace{0.3cm} \\langle{} \\textbf{Y}-\\textbf{c}^{*}, \\textbf{c} \\rangle{} = \\mathbb{E}\\big[{}(\\textbf{Y}-\\textbf{c}^{*})^{T}\\textbf{c}\\big]{} = (\\mathbb{E}[\\textbf{Y}]-\\textbf{c}^{*})^{T}\\textbf{c} = 0 $\n",
    "##### $ \\hspace{0.3cm} \\therefore{} \\forall{} \\, \\textbf{c} \\in{} \\mathbb{R}^{m}, \\;\\; (\\mathbb{E}[\\textbf{Y}]-\\textbf{c}^{*})^{T}\\textbf{c} = 0 \\; \\Rightarrow{} \\; \\textbf{c}^{*} = \\hat{\\textbf{Y}}^{*} = \\mathbb{E}[\\textbf{Y}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f76c5",
   "metadata": {},
   "source": [
    "#### **(3) 최소값** : \n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\mathbb{E}[\\|\\textbf{Y}-\\hat{\\textbf{Y}}^{*}\\|^{2}_{2}] = \\text{tr}\\big({}\\text{cov}(\\textbf{Y}, \\textbf{Y})\\big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9697f37",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e990af",
   "metadata": {},
   "source": [
    "> ## **선형 추정기(Linear estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fb1f1",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 확률 벡터 $ \\textbf{Y} $에 대한 추정기 $ \\hat{\\textbf{Y}} $를 아핀(affine) 함수 $ f(\\textbf{X}) $로 제한한 경우로 정의된 추정기\n",
    "#### $ = $ 부분공간 $ \\mathcal{V} $를 아핀 함수 $ f $로 해 집합을 제한한 MSE 최소화 문제\n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} =\\displaystyle{} \\argmin_{\\hat{\\textbf{Y}}\\in{}\\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\argmin_{f\\in{}\\mathcal{F}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-f(\\textbf{X})\\|^{2}_{2}\\big]{} $\n",
    "#### $ \\hspace{0.45cm} \\text{where } \\, \\mathcal{V} := \\{ \\hat{\\textbf{Y}} = f(\\textbf{X}) \\in{} L^{2}(\\Omega{};\\mathbb{R}^{m}) \\mid{} f \\in{} \\mathcal{F} \\}, \\;\\; \\mathcal{V} \\, \\text{ is closed subspace}. $\n",
    "#### $ \\hspace{0.45cm} \\text{and } \\, \\mathcal{F} := \\{ f : \\mathbb{R}^{n} \\rightarrow{} \\mathbb{R}^{m} \\mid{} f(\\textbf{x}) = Ax+\\textbf{b}, \\;\\; A \\in{} \\mathbb{R}^{m\\times{}n}, \\;\\; \\textbf{b} \\in{} \\mathbb{R}^{m} \\} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce7936",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 일반적으로 $ \\textbf{Y} $를 알고자 하나 직접 관측할 수 없는 확률 벡터(target R.V.), $ \\textbf{X} $를 관측 가능한 확률 벡터(observation R.V)로 설정함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d55ee2",
   "metadata": {},
   "source": [
    "#### **(2) 최적해** : \n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = A^{*} \\textbf{X} + \\textbf{b}^{*} $\n",
    "#### $ \\hspace{0.45cm} \\text{where } \\, A^{*} = \\text{cov}(\\textbf{Y},\\textbf{X})\\text{cov}(\\textbf{X},\\textbf{X})^{-1} \\;\\; \\text{ s.t. } \\, \\text{cov}(\\textbf{X},\\textbf{X}) \\, \\text{ is invertible}. $\n",
    "#### $ \\hspace{0.45cm} \\text{and } \\, \\textbf{b}^{*} = \\mathbb{E}[\\textbf{Y}] - A^{*} \\mathbb{E}[\\textbf{X}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de024a",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** \n",
    "##### $ \\hspace{0.15cm} \\text{method 1. vector differentiation} $\n",
    "##### $ \\hspace{0.3cm} $ **[~]**\n",
    "##### $ \\hspace{0.15cm} \\text{method 2. orthogonality principle} $\n",
    "##### $ \\hspace{0.3cm} \\text{define } \\, \\mathcal{X} = \\text{span} \\big({} \\{ \\textbf{X} \\} \\big){}, \\;\\; \\textbf{c} \\in{} \\mathcal{C} = \\text{span} \\big({} \\{ \\textbf{e}_{1}, \\textbf{e}_{2}, \\cdots{}, \\textbf{e}_{m} \\} \\big){} $\n",
    "##### $ \\hspace{0.3cm} \\text{and } \\, \\mathcal{V} = \\mathcal{X} \\oplus{} \\mathcal{C} = \\big({} \\{ \\{\\textbf{X}\\} \\cup{} \\{\\textbf{e}_{1}, \\textbf{e}_{2}, \\cdots{}, \\textbf{e}_{m}\\} \\} \\big){} $ \n",
    "##### $ \\hspace{0.3cm} \\text{let } \\, \\tilde{\\textbf{Y}} := \\textbf{Y} - \\mathbb{E}[\\textbf{Y}], \\;\\; \\tilde{\\textbf{X}} := \\textbf{X} - \\mathbb{E}[\\textbf{X}] \\;\\; (\\text{centralization}) $\n",
    "##### $ \\hspace{0.3cm} \\cdot{} \\, \\text{orthogonality to the constant subspace } \\, \\mathcal{C} $\n",
    "##### $ \\hspace{0.3cm} \\boldsymbol{\\epsilon{}} := \\textbf{Y} - (A\\textbf{X}+\\textbf{b}) = (\\tilde{\\textbf{Y}} + \\mathbb{E}[\\textbf{Y}]) - A(\\tilde{\\textbf{X}} + \\mathbb{E}[\\textbf{X}]) - \\textbf{b} $\n",
    "##### $ \\hspace{3.375cm} = (\\tilde{\\textbf{Y}} - A\\tilde{\\textbf{X}}) + (\\mathbb{E}[\\textbf{Y}] - \\textbf{b} - A\\mathbb{E}[\\textbf{X}]) $\n",
    "##### $ \\hspace{0.3cm} <\\boldsymbol{\\epsilon{}}^{*}, \\textbf{c}> = \\mathbb{E}[(\\boldsymbol{\\epsilon{}}^{*})^{T}\\textbf{c}] = (\\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}])^{T} \\textbf{c} = 0 \\;\\; \\because{} \\, \\boldsymbol{\\epsilon{}}^{*} \\perp{} \\mathcal{C} $\n",
    "##### $ \\hspace{0.3cm} \\forall{} \\, \\textbf{c} \\in{} \\mathbb{R}^{m}, \\;\\; (\\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}])^{T} \\textbf{c} = 0 \\; \\Rightarrow{} \\; \\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}] = \\textbf{0} $ \n",
    "##### $ \\hspace{0.3cm} \\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}] = \\mathbb{E}\\big[{} (\\tilde{\\textbf{Y}} - A^{*}\\tilde{\\textbf{X}}) + (\\mathbb{E}[\\textbf{Y}] - \\textbf{b}^{*} - A^{*}\\mathbb{E}[\\textbf{X}]) \\big]{} $ \n",
    "##### $ \\hspace{1.155cm} = \\mathbb{E}[\\tilde{\\textbf{Y}}] - A^{*}\\mathbb{E}[\\tilde{\\textbf{X}}] + \\mathbb{E}[\\textbf{Y}] - \\textbf{b}^{*} - A^{*}\\mathbb{E}[\\textbf{X}] $ \n",
    "##### $ \\hspace{1.155cm} = \\mathbb{E}[\\textbf{Y}] - \\textbf{b}^{*} - A^{*}\\mathbb{E}[\\textbf{X}] = \\textbf{0} $ \n",
    "##### $ \\hspace{0.3cm} \\textbf{b}^{*} = \\mathbb{E}[\\textbf{Y}] - A^{*}\\mathbb{E}[\\textbf{X}], \\;\\; \\boldsymbol{\\epsilon{}}^{*} = (\\tilde{\\textbf{Y}} - A^{*}\\tilde{\\textbf{X}}) $\n",
    "##### $ \\hspace{0.3cm} \\cdot{} \\, \\text{orthogonality to the } \\, X\\text{-induced linear subspace } \\, \\mathcal{X} $\n",
    "##### $ \\hspace{0.3cm} <\\boldsymbol{\\epsilon{}}^{*}, A\\textbf{X}> = \\mathbb{E}[(\\boldsymbol{\\epsilon{}}^{*})^{T}A\\textbf{X}] $\n",
    "##### $ \\hspace{2.1cm} = \\mathbb{E}\\bigg[{}\\text{tr}\\big({}(\\boldsymbol{\\epsilon{}}^{*})^{T}A\\textbf{X}\\big){}\\bigg]{} \\;\\; \\because{} \\, (\\boldsymbol{\\epsilon{}}^{*})^{T}A\\textbf{X} \\in{} \\mathbb{R}^{1\\times{}1} $\n",
    "##### $ \\hspace{2.1cm} = \\mathbb{E}\\bigg[{}\\text{tr}\\big({}A\\textbf{X}(\\boldsymbol{\\epsilon{}}^{*})^{T}\\big){}\\bigg]{} \\;\\; \\because{} \\, \\text{tr}(BCD) = \\text{tr}(CDB) = \\text{tr}(DBC) \\;\\; (\\text{cyclic}) $\n",
    "##### $ \\hspace{2.1cm} = \\text{tr}\\bigg({}A\\mathbb{E}\\big[{}\\textbf{X}(\\boldsymbol{\\epsilon{}}^{*})^{T}\\big]{}\\bigg){} = \\text{tr}\\bigg({}(A\\mathbb{E}\\big[{}\\textbf{X}(\\boldsymbol{\\epsilon{}}^{*})^{T}\\big]{})^{T}\\bigg){} \\;\\; \\because{} \\, \\text{tr}(B) = \\text{tr}(B^{T}) $ \n",
    "##### $ \\hspace{2.1cm} = \\text{tr}\\bigg({}\\mathbb{E}\\big[{}\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}\\big]{}A^{T} \\bigg){}  = \\text{tr}\\bigg( A^{T}{}\\mathbb{E}\\big[{}\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}\\big]{} \\bigg){} $\n",
    "##### $ \\hspace{2.1cm} = <A, \\mathbb{E}\\big[{}\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}\\big]{}>_{\\text{F}} = 0 \\;\\; \\text{ where } \\, <\\cdot{}>_{\\text{F}} \\, \\text{ is frobenius inner prod}. $\n",
    "##### $ \\hspace{0.3cm} \\forall{} \\, A \\in{} \\mathbb{R}^{m\\times{}n}, \\;\\; <A, \\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}]>_{\\text{F}} = 0 \\; \\Rightarrow{} \\; \\mathbb{E}\\big[{}\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}\\big]{} = 0_{m\\times{}n} $ \n",
    "##### $ \\hspace{0.3cm} \\mathbb{E}[\\boldsymbol{\\epsilon{}}^{*}\\textbf{X}^{T}] = \\mathbb{E}\\big[{}(\\tilde{\\textbf{Y}} - A\\tilde{\\textbf{X}})(\\tilde{\\textbf{X}}+\\mathbb{E}[\\textbf{X}])^{T} \\big]{} $\n",
    "##### $ \\hspace{1.625cm} = \\mathbb{E}\\big[{}(\\tilde{\\textbf{Y}} - A\\tilde{\\textbf{X}})(\\tilde{\\textbf{X}}^{T}+\\mathbb{E}[\\textbf{X}]^{T}) \\big]{} = \\mathbb{E}\\big[{}(\\tilde{\\textbf{Y}} - A\\tilde{\\textbf{X}})\\tilde{\\textbf{X}}^{T}+(\\tilde{\\textbf{Y}} - A\\tilde{\\textbf{X}})\\mathbb{E}[\\textbf{X}]^{T} \\big]{} $\n",
    "##### $ \\hspace{1.625cm} = \\mathbb{E}\\big[{}\\tilde{\\textbf{Y}}\\tilde{\\textbf{X}}^{T} - A\\tilde{\\textbf{X}}\\tilde{\\textbf{X}}^{T} + \\mathbb{E}\\big[{}\\tilde{\\textbf{Y}}\\big]\\mathbb{E}[\\textbf{X}]^{T} - A\\tilde{\\textbf{X}}\\mathbb{E}[\\textbf{X}]^{T} \\big]{} $\n",
    "##### $ \\hspace{1.625cm} = \\mathbb{E}\\big[{}\\tilde{\\textbf{Y}}\\tilde{\\textbf{X}}^{T}\\big]{} - A\\mathbb{E}\\big[{}\\tilde{\\textbf{X}}\\tilde{\\textbf{X}}^{T}\\big]{} + \\mathbb{E}\\big[{}\\tilde{\\textbf{Y}}\\big]{} \\mathbb{E}[\\textbf{X}]^{T} - A\\mathbb{E}\\big[{}\\tilde{\\textbf{X}}\\big]\\mathbb{E}[\\textbf{X}]^{T} $\n",
    "##### $ \\hspace{1.625cm} = \\mathbb{E}\\big[{}\\tilde{\\textbf{Y}}\\tilde{\\textbf{X}}^{T}\\big]{} - A\\mathbb{E}\\big[{}\\tilde{\\textbf{X}}\\tilde{\\textbf{X}}^{T}\\big]{} \\;\\; \\because{} \\, \\mathbb{E}[\\tilde{\\textbf{Y}}] = \\mathbb{E}[\\tilde{\\textbf{X}}] = \\textbf{0} $\n",
    "##### $ \\hspace{1.625cm} = \\mathbb{E}\\big[{}(\\textbf{Y} - \\mathbb{E}[\\textbf{Y}])(\\textbf{X} - \\mathbb{E}[\\textbf{X}])^{T}\\big]{} - A\\mathbb{E}\\big[{}(\\textbf{X} - \\mathbb{E}[\\textbf{X}])(\\textbf{X} - \\mathbb{E}[\\textbf{X}])^{T}\\big]{} $\n",
    "##### $ \\hspace{1.625cm} = \\text{cov}(\\textbf{Y},\\textbf{X}) - A \\text{cov}(\\textbf{X},\\textbf{X}) = 0_{m\\times{}n} $\n",
    "##### $ \\hspace{0.3cm} A^{*} = \\text{cov}(\\textbf{Y},\\textbf{X})\\text{cov}(\\textbf{X},\\textbf{X})^{-1} \\;\\; \\text{ s.t. } \\, \\text{cov}(\\textbf{X},\\textbf{X}) \\, \\text{ is invertible}. $\n",
    "##### $ \\hspace{0.15cm} \\therefore{} A^{*} = \\text{cov}(\\textbf{Y},\\textbf{X})\\text{cov}(\\textbf{X},\\textbf{X})^{-1}, \\;\\; \\textbf{b}^{*} = \\mathbb{E}[\\textbf{Y}] - A^{*}\\mathbb{E}[\\textbf{X}] \\;\\; \\text{ s.t. } \\, \\text{cov}(\\textbf{X},\\textbf{X}) \\, \\text{ is invertible}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625168e",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** $ \\text{cov}(\\textbf{X}, \\textbf{X}) $가 비가역 행렬(singular matrix)이라면, 유사 역행렬(pseudoinverse matrix)을 구해서 근사함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3595b",
   "metadata": {},
   "source": [
    "#### **(3) 최소값** : \n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\mathbb{E}[\\|\\textbf{Y}-\\hat{\\textbf{Y}}^{*}\\|^{2}_{2}] $\n",
    "#### $ \\hspace{3.3675cm} = \\text{tr}\\big({}\\text{cov}(\\textbf{Y}, \\textbf{Y}) - \\text{cov}(\\textbf{Y}, \\textbf{X}) \\text{cov}(\\textbf{X}, \\textbf{X})^{-1} \\text{cov}(\\textbf{X}, \\textbf{Y}) \\big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c48e8d",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62094685",
   "metadata": {},
   "source": [
    "> ## **비선형 추정기(Non-linear estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7c302",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 확률 벡터 $ \\textbf{Y} $에 대한 추정기 $ \\hat{\\textbf{Y}} $를 비선형 함수 $ g(\\textbf{X}) $로 제한한 경우로 정의된 추정기\n",
    "#### $ = \\mathcal{V} $를 X-가측인 부분공간으로 정의한 MSE 최소화 문제\n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\displaystyle{} \\argmin_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\argmin_{g \\in{} \\mathcal{G}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-g(\\textbf{X})\\|^{2}_{2}\\big]{} $\n",
    "#### $ \\hspace{0.45cm} \\text{where } \\, \\mathcal{V} := \\{ \\hat{\\textbf{Y}} = g(\\textbf{X}) \\in{} L^{2}(\\Omega{};\\mathbb{R}^{m}) \\mid{} g \\in{} \\mathcal{G} \\}, \\;\\; \\mathcal{V} \\, \\text{ is closed subspace}. $\n",
    "#### $ \\hspace{0.45cm} \\text{and } \\, \\mathcal{G} := \\{ g : \\mathbb{R}^{n} \\rightarrow{} \\mathbb{R}^{m} \\mid{} g(\\textbf{X}) \\, \\text{ is } \\, \\sigma{}(\\textbf{X})\\text{-measurable} \\} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47aa9a",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** X-가측($ \\sigma{}(\\textbf{X})\\text{-measurable} $)이란 추정기 $ \\hat{\\textbf{Y}} $가 오직 $ \\textbf{X} $의 값(정보;$ \\sigma{}$-대수)으로만 결정된다는 의미임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759fa393",
   "metadata": {},
   "source": [
    "#### **(2) 최적해** : \n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\mathbb{E}[\\textbf{Y}|\\textbf{X}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd00f4",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** \n",
    "##### $ \\hspace{0.15cm} $ **[~]** (CH01. MMSE CHUNK-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c74a93",
   "metadata": {},
   "source": [
    "#### **(3) 최소값** : \n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\mathbb{E}[\\|\\textbf{Y}-\\hat{\\textbf{Y}}^{*}\\|^{2}_{2}] = \\mathbb{E}[\\|\\textbf{Y}-\\mathbb{E}[\\textbf{Y}|\\textbf{X}]\\|^{2}_{2}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164363dd",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b19ff",
   "metadata": {},
   "source": [
    "> ## (Theorem 1-7) **Unbiasedness of MMSE estimators**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa26288",
   "metadata": {},
   "source": [
    "#### 상기 추정기(자명, 상수, 선형, 비선형)들의 최적해($ \\hat{\\textbf{Y}} $)는 불편 예측기(unbiased predictor)이다.\n",
    "#### $ \\Rrightarrow{} \\mathbb{E}[\\hat{\\textbf{Y}}^{*}] = \\mathbb{E}[\\textbf{Y}]  $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ff60b",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ec6a1",
   "metadata": {},
   "source": [
    "> ## (Theorem 1-8) **Estimator hierarchy and MSE monotonicity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea36f7",
   "metadata": {},
   "source": [
    "#### **(1)** 상수 추정기의 부분공간은 선형 추정기의 부분공간이고, 선형 추정기는 X-측정가능한(비선형을 포함한) 추정기로 이루어진 더 큰 부분공간이다.\n",
    "#### $ \\Rrightarrow{} \\mathcal{V}_{\\text{constant}} \\subset{} \\mathcal{V}_{\\text{linear}} \\subset{} \\mathcal{V}_{\\text{non-linear}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f75708",
   "metadata": {},
   "source": [
    "#### **(2)** 부분공간이 확장될수록 MSE 문제에서 $ \\textbf{Y} $를 더 잘 근사할 수 있다.\n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}_{\\text{non-linear}}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} \\leq{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}_{\\text{linear}}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} \\leq{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}_{\\text{constant}}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} \\;\\; \\because{} \\text{theorem 1-6} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16c91a",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2925526",
   "metadata": {},
   "source": [
    "> ## **가우시안 추정기(Joint Gaussian estimator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb215708",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 두 확률 벡터 $ \\textbf{X}, \\textbf{Y} $의 결합 분포가 가우시안(정규) 분포인 경우로 정의된 추정기\n",
    "#### $ = $ 부분공간 $ \\mathcal{V} $를 X-가측이며, 두 확률 벡터를 가우시안 정규 분포로 제한한 MSE 최소화 문제\n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = \\displaystyle{} \\argmin_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\argmin_{g \\in{} \\mathcal{G}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-g(\\textbf{X})\\|^{2}_{2}\\big]{} $\n",
    "#### $ \\hspace{0.45cm} \\text{s.t. } \\, \\begin{bmatrix} \\textbf{X} \\\\ \\textbf{Y} \\end{bmatrix} \\sim{} N(\\begin{bmatrix} \\mathbb{E}[\\textbf{X}] \\\\ \\mathbb{E}[\\textbf{Y}] \\end{bmatrix}, \\begin{bmatrix} \\text{cov}(\\textbf{X}, \\textbf{X}) & \\text{cov}(\\textbf{X}, \\textbf{Y}) \\\\ \\text{cov}(\\textbf{Y}, \\textbf{X}) & \\text{cov}(\\textbf{Y}, \\textbf{Y}) \\end{bmatrix}) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05eecc2",
   "metadata": {},
   "source": [
    "#### **(2) 최적해** : \n",
    "#### $ \\Rrightarrow{} \\hat{\\textbf{Y}}^{*} = A^{*} \\textbf{X} + \\textbf{b}^{*} $\n",
    "#### $ \\hspace{0.45cm} \\text{where } \\, A^{*} = \\text{cov}(\\textbf{Y},\\textbf{X})\\text{cov}(\\textbf{X},\\textbf{X})^{-1} \\;\\; \\text{ s.t. } \\, \\text{cov}(\\textbf{X},\\textbf{X}) \\, \\text{ is invertible}. $\n",
    "#### $ \\hspace{0.45cm} \\text{and } \\, \\textbf{b}^{*} = \\mathbb{E}[\\textbf{Y}] - A^{*} \\mathbb{E}[\\textbf{X}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53484aa",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** \n",
    "##### $ \\hspace{0.15cm} $ **[~]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c446a",
   "metadata": {},
   "source": [
    "#### **(3) 최소값** : \n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\mathbb{E}[\\|\\textbf{Y}-\\hat{\\textbf{Y}}^{*}\\|^{2}_{2}] $\n",
    "#### $ \\hspace{3.3675cm} = \\text{tr}\\big({}\\text{cov}(\\textbf{Y}, \\textbf{Y}) - \\text{cov}(\\textbf{Y}, \\textbf{X}) \\text{cov}(\\textbf{X}, \\textbf{X})^{-1} \\text{cov}(\\textbf{X}, \\textbf{Y}) \\big){} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ae02b",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98103c3",
   "metadata": {},
   "source": [
    "> ## (Theorem 1-9) **Equivalence of LMMSE and MMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bbff7",
   "metadata": {},
   "source": [
    "#### 두 확률 벡터 $ \\textbf{X}, \\textbf{Y} $가 결합 가우시안 분포일 때 MSE는 선형 추정기의 MSE와 동일하다.\n",
    "#### $ \\Rrightarrow{} \\displaystyle{} \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}_{\\text{non-linear}}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} = \\min_{\\hat{\\textbf{Y}} \\in{} \\mathcal{V}_{\\text{linear}}} \\mathbb{E}\\big[{}\\|\\textbf{Y}-\\hat{\\textbf{Y}}\\|^{2}_{2}\\big]{} $\n",
    "#### $ \\hspace{0.45cm} \\text{s.t. } \\, \\begin{bmatrix} \\textbf{X} \\\\ \\textbf{Y} \\end{bmatrix} \\sim{} N(\\begin{bmatrix} \\mathbb{E}[\\textbf{X}] \\\\ \\mathbb{E}[\\textbf{Y}] \\end{bmatrix}, \\begin{bmatrix} \\text{cov}(\\textbf{X}, \\textbf{X}) & \\text{cov}(\\textbf{X}, \\textbf{Y}) \\\\ \\text{cov}(\\textbf{Y}, \\textbf{X}) & \\text{cov}(\\textbf{Y}, \\textbf{Y}) \\end{bmatrix}) $ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
